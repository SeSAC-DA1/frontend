# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ
PostgreSQLê³¼ í†µí•©ëœ ì‹¤ì‹œê°„ ì‚¬ìš©ì í–‰ë™ í•™ìŠµ ë° ì¶”ì²œì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
"""

import asyncio
import logging
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import json
import numpy as np
import torch
from dataclasses import dataclass
from collections import defaultdict
import asyncpg
from .connection import DatabaseManager, UserBehaviorTracker

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class UserInteraction:
    """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° í´ë˜ìŠ¤"""
    user_id: str
    vehicle_id: str
    interaction_type: str  # 'view', 'like', 'inquiry', 'purchase', 'compare'
    timestamp: datetime
    session_id: str
    context: Dict[str, Any]
    engagement_score: float

@dataclass
class LearningBatch:
    """ì‹¤ì‹œê°„ í•™ìŠµì„ ìœ„í•œ ë°°ì¹˜ ë°ì´í„°"""
    interactions: List[UserInteraction]
    batch_id: str
    created_at: datetime
    priority: int  # 1=high, 2=medium, 3=low

class RealTimeLearningEngine:
    """ì‹¤ì‹œê°„ í•™ìŠµ ì—”ì§„"""

    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        self.behavior_tracker = UserBehaviorTracker(db_manager)
        self.learning_queue = asyncio.Queue()
        self.user_embeddings = {}
        self.vehicle_embeddings = {}
        self.learning_active = False

        # í•™ìŠµ ë§¤ê°œë³€ìˆ˜
        self.batch_size = 32
        self.learning_rate = 0.001
        self.embedding_dim = 64
        self.update_threshold = 10  # ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜

    async def start_learning_pipeline(self):
        """ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        self.learning_active = True

        # ë³‘ë ¬ ì‘ì—… ì‹œì‘
        tasks = [
            asyncio.create_task(self._interaction_processor()),
            asyncio.create_task(self._batch_learner()),
            asyncio.create_task(self._embedding_updater()),
            asyncio.create_task(self._preference_calculator())
        ]

        logger.info("ğŸš€ ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        await asyncio.gather(*tasks)

    async def stop_learning_pipeline(self):
        """ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€"""
        self.learning_active = False
        logger.info("â¸ï¸ ì‹¤ì‹œê°„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€")

    async def process_user_interaction(self, interaction_data: Dict[str, Any]) -> bool:
        """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ì²˜ë¦¬"""
        try:
            # ìƒí˜¸ì‘ìš© ë°ì´í„° ê²€ì¦
            if not self._validate_interaction(interaction_data):
                logger.warning(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ìƒí˜¸ì‘ìš© ë°ì´í„°: {interaction_data}")
                return False

            # UserInteraction ê°ì²´ ìƒì„±
            interaction = UserInteraction(
                user_id=interaction_data['user_id'],
                vehicle_id=interaction_data['vehicle_id'],
                interaction_type=interaction_data['interaction_type'],
                timestamp=datetime.now(),
                session_id=interaction_data.get('session_id', 'unknown'),
                context=interaction_data.get('context', {}),
                engagement_score=self._calculate_engagement_score(interaction_data)
            )

            # ì¦‰ì‹œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            await self.behavior_tracker.track_user_interaction(interaction_data)

            # í•™ìŠµ íì— ì¶”ê°€
            await self.learning_queue.put(interaction)

            # ì‹¤ì‹œê°„ ì¶”ì²œ ì—…ë°ì´íŠ¸ (ê³ ì°¸ì—¬ë„ ìƒí˜¸ì‘ìš©ì˜ ê²½ìš°)
            if interaction.engagement_score > 0.7:
                await self._immediate_recommendation_update(interaction)

            logger.info(f"âœ… ìƒí˜¸ì‘ìš© ì²˜ë¦¬ ì™„ë£Œ: {interaction.user_id} -> {interaction.vehicle_id}")
            return True

        except Exception as e:
            logger.error(f"âŒ ìƒí˜¸ì‘ìš© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False

    async def _interaction_processor(self):
        """ìƒí˜¸ì‘ìš© ì²˜ë¦¬ê¸° (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
        while self.learning_active:
            try:
                # íì—ì„œ ìƒí˜¸ì‘ìš© ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 1ì´ˆ ëŒ€ê¸°)
                interaction = await asyncio.wait_for(
                    self.learning_queue.get(), timeout=1.0
                )

                # ìƒí˜¸ì‘ìš© ë¶„ì„ ë° ì²˜ë¦¬
                await self._analyze_interaction(interaction)

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"âŒ ìƒí˜¸ì‘ìš© ì²˜ë¦¬ê¸° ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1)

    async def _batch_learner(self):
        """ë°°ì¹˜ í•™ìŠµê¸° (ì£¼ê¸°ì  ì‹¤í–‰)"""
        while self.learning_active:
            try:
                # 5ë¶„ë§ˆë‹¤ ë°°ì¹˜ í•™ìŠµ ì‹¤í–‰
                await asyncio.sleep(300)

                # ìµœê·¼ ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘
                batch_data = await self._collect_batch_data()

                if len(batch_data) >= self.batch_size:
                    await self._execute_batch_learning(batch_data)

            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ í•™ìŠµê¸° ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)

    async def _embedding_updater(self):
        """ì„ë² ë”© ì—…ë°ì´í„° (ì£¼ê¸°ì  ì—…ë°ì´íŠ¸)"""
        while self.learning_active:
            try:
                # 10ë¶„ë§ˆë‹¤ ì„ë² ë”© ì—…ë°ì´íŠ¸
                await asyncio.sleep(600)

                # ì‚¬ìš©ì ë° ì°¨ëŸ‰ ì„ë² ë”© ì—…ë°ì´íŠ¸
                await self._update_user_embeddings()
                await self._update_vehicle_embeddings()

                logger.info("ğŸ”„ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"âŒ ì„ë² ë”© ì—…ë°ì´í„° ì˜¤ë¥˜: {e}")
                await asyncio.sleep(120)

    async def _preference_calculator(self):
        """ì„ í˜¸ë„ ê³„ì‚°ê¸° (ì‹¤ì‹œê°„ ê³„ì‚°)"""
        while self.learning_active:
            try:
                # 2ë¶„ë§ˆë‹¤ ì‚¬ìš©ì ì„ í˜¸ë„ ì¬ê³„ì‚°
                await asyncio.sleep(120)

                # í™œì„± ì‚¬ìš©ìë“¤ì˜ ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
                active_users = await self._get_active_users()

                for user_id in active_users:
                    await self._recalculate_user_preferences(user_id)

                logger.info(f"ğŸ“Š {len(active_users)}ëª… ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"âŒ ì„ í˜¸ë„ ê³„ì‚°ê¸° ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)

    async def _analyze_interaction(self, interaction: UserInteraction):
        """ìƒí˜¸ì‘ìš© ë¶„ì„"""
        try:
            # ìƒí˜¸ì‘ìš© íƒ€ì…ë³„ ê°€ì¤‘ì¹˜
            weights = {
                'view': 0.1,
                'like': 0.3,
                'inquiry': 0.6,
                'compare': 0.4,
                'purchase': 1.0
            }

            weight = weights.get(interaction.interaction_type, 0.1)

            # ì‚¬ìš©ì ì„ í˜¸ë„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
            await self._update_immediate_preference(
                interaction.user_id,
                interaction.vehicle_id,
                weight * interaction.engagement_score
            )

            # ì°¨ëŸ‰ ì¸ê¸°ë„ ì—…ë°ì´íŠ¸
            await self._update_vehicle_popularity(
                interaction.vehicle_id,
                weight
            )

        except Exception as e:
            logger.error(f"âŒ ìƒí˜¸ì‘ìš© ë¶„ì„ ì‹¤íŒ¨: {e}")

    async def _immediate_recommendation_update(self, interaction: UserInteraction):
        """ì¦‰ì‹œ ì¶”ì²œ ì—…ë°ì´íŠ¸ (ê³ ì°¸ì—¬ë„ ìƒí˜¸ì‘ìš©)"""
        try:
            user_id = interaction.user_id
            vehicle_id = interaction.vehicle_id

            # ìœ ì‚¬í•œ ì°¨ëŸ‰ ì°¾ê¸°
            similar_vehicles = await self._find_similar_vehicles(vehicle_id)

            # ì‚¬ìš©ìì˜ ì‹¤ì‹œê°„ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            await self._update_user_recommendations(user_id, similar_vehicles)

            logger.info(f"âš¡ ì¦‰ì‹œ ì¶”ì²œ ì—…ë°ì´íŠ¸: {user_id}")

        except Exception as e:
            logger.error(f"âŒ ì¦‰ì‹œ ì¶”ì²œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    async def _collect_batch_data(self) -> List[UserInteraction]:
        """ë°°ì¹˜ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ìµœê·¼ 5ë¶„ê°„ì˜ ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘
            cutoff_time = datetime.now() - timedelta(minutes=5)

            query = """
                SELECT user_id, vehicle_id, interaction_type, timestamp,
                       session_id, context_data, engagement_score
                FROM user_interactions
                WHERE timestamp > $1
                ORDER BY timestamp DESC
                LIMIT 1000
            """

            async with self.db_manager.get_connection() as conn:
                rows = await conn.fetch(query, cutoff_time)

                interactions = []
                for row in rows:
                    interaction = UserInteraction(
                        user_id=row['user_id'],
                        vehicle_id=row['vehicle_id'],
                        interaction_type=row['interaction_type'],
                        timestamp=row['timestamp'],
                        session_id=row['session_id'],
                        context=json.loads(row['context_data'] or '{}'),
                        engagement_score=row['engagement_score'] or 0.5
                    )
                    interactions.append(interaction)

                return interactions

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_batch_learning(self, batch_data: List[UserInteraction]):
        """ë°°ì¹˜ í•™ìŠµ ì‹¤í–‰"""
        try:
            # ë°°ì¹˜ ë°ì´í„°ë¥¼ í•™ìŠµ í˜•íƒœë¡œ ë³€í™˜
            user_ids = [int(interaction.user_id) for interaction in batch_data]
            vehicle_ids = [int(interaction.vehicle_id) for interaction in batch_data]
            ratings = [interaction.engagement_score for interaction in batch_data]

            # PyTorch í…ì„œë¡œ ë³€í™˜
            user_tensor = torch.LongTensor(user_ids)
            vehicle_tensor = torch.LongTensor(vehicle_ids)
            rating_tensor = torch.FloatTensor(ratings)

            # ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ NCF ëª¨ë¸ ì‚¬ìš©)
            model = await self._load_ncf_model()

            if model:
                # ë°°ì¹˜ í•™ìŠµ ì‹¤í–‰
                loss = await self._train_batch(model, user_tensor, vehicle_tensor, rating_tensor)
                logger.info(f"ğŸ“š ë°°ì¹˜ í•™ìŠµ ì™„ë£Œ - Loss: {loss:.4f}")

                # ëª¨ë¸ ì €ì¥
                await self._save_model(model)

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    async def _update_user_embeddings(self):
        """ì‚¬ìš©ì ì„ë² ë”© ì—…ë°ì´íŠ¸"""
        try:
            # ìµœê·¼ í™œì„± ì‚¬ìš©ìë“¤ì˜ ì„ë² ë”© ì¬ê³„ì‚°
            query = """
                SELECT DISTINCT user_id
                FROM user_interactions
                WHERE timestamp > NOW() - INTERVAL '1 hour'
            """

            async with self.db_manager.get_connection() as conn:
                rows = await conn.fetch(query)

                for row in rows:
                    user_id = row['user_id']
                    # ì‚¬ìš©ì ì„ë² ë”© ì¬ê³„ì‚° ë¡œì§
                    embedding = await self._calculate_user_embedding(user_id)
                    self.user_embeddings[user_id] = embedding

        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    async def _update_vehicle_embeddings(self):
        """ì°¨ëŸ‰ ì„ë² ë”© ì—…ë°ì´íŠ¸"""
        try:
            # ìµœê·¼ ìƒí˜¸ì‘ìš©ì´ ìˆëŠ” ì°¨ëŸ‰ë“¤ì˜ ì„ë² ë”© ì¬ê³„ì‚°
            query = """
                SELECT DISTINCT vehicle_id
                FROM user_interactions
                WHERE timestamp > NOW() - INTERVAL '1 hour'
            """

            async with self.db_manager.get_connection() as conn:
                rows = await conn.fetch(query)

                for row in rows:
                    vehicle_id = row['vehicle_id']
                    # ì°¨ëŸ‰ ì„ë² ë”© ì¬ê³„ì‚° ë¡œì§
                    embedding = await self._calculate_vehicle_embedding(vehicle_id)
                    self.vehicle_embeddings[vehicle_id] = embedding

        except Exception as e:
            logger.error(f"âŒ ì°¨ëŸ‰ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _validate_interaction(self, interaction_data: Dict[str, Any]) -> bool:
        """ìƒí˜¸ì‘ìš© ë°ì´í„° ê²€ì¦"""
        required_fields = ['user_id', 'vehicle_id', 'interaction_type']

        for field in required_fields:
            if field not in interaction_data:
                return False

        valid_types = ['view', 'like', 'inquiry', 'compare', 'purchase']
        if interaction_data['interaction_type'] not in valid_types:
            return False

        return True

    def _calculate_engagement_score(self, interaction_data: Dict[str, Any]) -> float:
        """ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚°"""
        base_scores = {
            'view': 0.1,
            'like': 0.3,
            'inquiry': 0.7,
            'compare': 0.5,
            'purchase': 1.0
        }

        base_score = base_scores.get(interaction_data['interaction_type'], 0.1)

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì ìš©
        context = interaction_data.get('context', {})

        # ì²´ë¥˜ ì‹œê°„ ê°€ì¤‘ì¹˜
        duration = context.get('duration_seconds', 10)
        duration_weight = min(duration / 60, 2.0)  # ìµœëŒ€ 2ë°°

        # ë°˜ë³µ ë°©ë¬¸ ê°€ì¤‘ì¹˜
        repeat_visit = context.get('repeat_visit', False)
        repeat_weight = 1.2 if repeat_visit else 1.0

        final_score = base_score * duration_weight * repeat_weight
        return min(final_score, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ

    async def _get_active_users(self) -> List[str]:
        """í™œì„± ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
        try:
            query = """
                SELECT DISTINCT user_id
                FROM user_interactions
                WHERE timestamp > NOW() - INTERVAL '10 minutes'
                LIMIT 100
            """

            async with self.db_manager.get_connection() as conn:
                rows = await conn.fetch(query)
                return [row['user_id'] for row in rows]

        except Exception as e:
            logger.error(f"âŒ í™œì„± ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def _load_ncf_model(self):
        """NCF ëª¨ë¸ ë¡œë“œ"""
        try:
            # ê¸°ì¡´ PyTorch NCF ëª¨ë¸ ë¡œë“œ ë¡œì§
            model_path = "models/pytorch_ncf_real.py"
            # ì‹¤ì œ ëª¨ë¸ ë¡œë“œ êµ¬í˜„ í•„ìš”
            return None  # ì„ì‹œ
        except Exception as e:
            logger.error(f"âŒ NCF ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    async def _train_batch(self, model, user_tensor, vehicle_tensor, rating_tensor):
        """ë°°ì¹˜ í›ˆë ¨"""
        try:
            # ì‹¤ì œ PyTorch í›ˆë ¨ ë¡œì§ êµ¬í˜„ í•„ìš”
            return 0.0  # ì„ì‹œ
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return float('inf')

    async def _save_model(self, model):
        """ëª¨ë¸ ì €ì¥"""
        try:
            # ëª¨ë¸ ì €ì¥ ë¡œì§ êµ¬í˜„ í•„ìš”
            pass
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

class RealtimeRecommendationCache:
    """ì‹¤ì‹œê°„ ì¶”ì²œ ìºì‹œ"""

    def __init__(self, redis_client=None):
        self.redis_client = redis_client
        self.local_cache = {}
        self.cache_ttl = 300  # 5ë¶„

    async def get_user_recommendations(self, user_id: str) -> List[Dict]:
        """ì‚¬ìš©ì ì¶”ì²œ ì¡°íšŒ"""
        try:
            cache_key = f"recommendations:{user_id}"

            if self.redis_client:
                # Redisì—ì„œ ì¡°íšŒ
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    return json.loads(cached_data)

            # ë¡œì»¬ ìºì‹œì—ì„œ ì¡°íšŒ
            if user_id in self.local_cache:
                cache_data = self.local_cache[user_id]
                if datetime.now() - cache_data['timestamp'] < timedelta(seconds=self.cache_ttl):
                    return cache_data['recommendations']

            return []

        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def update_user_recommendations(self, user_id: str, recommendations: List[Dict]):
        """ì‚¬ìš©ì ì¶”ì²œ ì—…ë°ì´íŠ¸"""
        try:
            cache_key = f"recommendations:{user_id}"
            recommendations_json = json.dumps(recommendations)

            if self.redis_client:
                # Redisì— ì €ì¥
                await self.redis_client.setex(cache_key, self.cache_ttl, recommendations_json)

            # ë¡œì»¬ ìºì‹œì— ì €ì¥
            self.local_cache[user_id] = {
                'recommendations': recommendations,
                'timestamp': datetime.now()
            }

            logger.info(f"ğŸ’¾ ì¶”ì²œ ìºì‹œ ì—…ë°ì´íŠ¸: {user_id}")

        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_realtime_engine = None
_recommendation_cache = None

async def get_realtime_engine() -> RealTimeLearningEngine:
    """ì‹¤ì‹œê°„ í•™ìŠµ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ"""
    global _realtime_engine

    if _realtime_engine is None:
        db_manager = DatabaseManager()
        _realtime_engine = RealTimeLearningEngine(db_manager)

    return _realtime_engine

async def get_recommendation_cache() -> RealtimeRecommendationCache:
    """ì¶”ì²œ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ"""
    global _recommendation_cache

    if _recommendation_cache is None:
        _recommendation_cache = RealtimeRecommendationCache()

    return _recommendation_cache