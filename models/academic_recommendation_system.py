"""
ë…¼ë¬¸ ê¸°ë°˜ ì°¨ëŸ‰ ì¶”ì²œ ì‹œìŠ¤í…œ - PyCaret ì™„ì „ ì œê±°
Academic Paper-Based Recommendation Engine

ì°¸ê³  ë…¼ë¬¸:
1. Neural Collaborative Filtering (He et al. 2017)
2. Wide & Deep Learning (Cheng et al. 2016)
3. Matrix Factorization (Koren, 2009)
4. BPR: Bayesian Personalized Ranking (Rendle et al. 2009)
5. LightFM: Learning Hybrid Recommender Systems (Kula, 2015)
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import logging
import warnings
from sqlalchemy import create_engine
import pickle
from datetime import datetime
warnings.filterwarnings('ignore')

# ë…¼ë¬¸ ê¸°ë°˜ ì¶”ì²œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from surprise import SVD, NMF, KNNBasic, Dataset, Reader, accuracy
    from surprise.model_selection import train_test_split, GridSearchCV
    from surprise import AlgoBase, PredictionImpossible
    SURPRISE_AVAILABLE = True
    print("OK Surprise (Matrix Factorization) - Available")
except ImportError:
    SURPRISE_AVAILABLE = False
    print("X Surprise - Not Available")

try:
    import tensorflow as tf
    import tensorflow_recommenders as tfrs
    from tensorflow import keras
    TENSORFLOW_AVAILABLE = True
    print("âœ… TensorFlow Recommenders (Neural CF) - Available")
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âŒ TensorFlow Recommenders - Not Available")

try:
    from lightfm import LightFM
    from lightfm.data import Dataset as LFMDataset
    from lightfm.evaluation import auc_score, precision_at_k
    LIGHTFM_AVAILABLE = True
    print("âœ… LightFM (Hybrid CF+Content) - Available")
except ImportError:
    LIGHTFM_AVAILABLE = False
    print("âŒ LightFM - Not Available")

try:
    import implicit
    from implicit.als import AlternatingLeastSquares
    from implicit.bpr import BayesianPersonalizedRanking
    from implicit.evaluation import ranking_metrics_at_k
    IMPLICIT_AVAILABLE = True
    print("âœ… Implicit (BPR, Fast ALS) - Available")
except ImportError:
    IMPLICIT_AVAILABLE = False
    print("âŒ Implicit - Not Available")

class AcademicCarRecommendationSystem:
    """
    ğŸ“ ë…¼ë¬¸ ê¸°ë°˜ ì°¨ëŸ‰ ì¶”ì²œ ì‹œìŠ¤í…œ

    êµ¬í˜„ ì•Œê³ ë¦¬ì¦˜:
    1. Matrix Factorization (Koren, 2009) via Surprise SVD
    2. Neural Collaborative Filtering (He et al. 2017) via TensorFlow
    3. Wide & Deep Learning (Cheng et al. 2016) via TF Recommenders
    4. Hybrid CF+Content (Kula, 2015) via LightFM
    5. BPR (Rendle et al. 2009) via Implicit
    """

    def __init__(self):
        self.models = {}
        self.car_data = None
        self.user_ratings = None
        self.user_features = None
        self.item_features = None
        self.interaction_matrix = None
        self.engine = None
        self.is_trained = False
        self.logger = self._setup_logger()

        # ë…¼ë¬¸ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        self.hyperparameters = {
            # Matrix Factorization (Koren, 2009)
            'surprise_svd': {
                'n_factors': 100,       # ë…¼ë¬¸ ê¶Œì¥: 50-200
                'lr_all': 0.005,        # ë…¼ë¬¸ ê¶Œì¥: 0.001-0.01
                'reg_all': 0.02,        # ë…¼ë¬¸ ê¶Œì¥: 0.01-0.1
                'n_epochs': 100         # ë…¼ë¬¸ ê¶Œì¥: 50-200
            },

            # Neural CF (He et al. 2017)
            'neural_cf': {
                'embedding_dim': 64,    # ë…¼ë¬¸ ì‹¤í—˜: 8,16,32,64
                'hidden_units': [256, 128, 64],  # ë…¼ë¬¸ êµ¬ì¡°
                'dropout_rate': 0.2,    # ë…¼ë¬¸ ê¶Œì¥: 0.0-0.5
                'learning_rate': 0.001, # ë…¼ë¬¸ ê¶Œì¥: 0.0001-0.01
                'regularization': 0.01  # ë…¼ë¬¸ ê¶Œì¥: 0.001-0.1
            },

            # LightFM (Kula, 2015)
            'lightfm': {
                'no_components': 64,    # ë…¼ë¬¸ ì‹¤í—˜: 10-300
                'learning_rate': 0.05,  # ë…¼ë¬¸ ê¶Œì¥: 0.01-0.1
                'loss': 'warp',         # ë…¼ë¬¸ ì¶”ì²œ: warp, bpr
                'epochs': 100,          # ë…¼ë¬¸ ê¶Œì¥: 50-200
                'item_alpha': 1e-6,     # ë…¼ë¬¸ ì •ê·œí™”
                'user_alpha': 1e-6      # ë…¼ë¬¸ ì •ê·œí™”
            },

            # BPR (Rendle et al. 2009)
            'bpr_implicit': {
                'factors': 64,          # ë…¼ë¬¸ ì‹¤í—˜: 10-100
                'learning_rate': 0.01,  # ë…¼ë¬¸ ê¶Œì¥: 0.001-0.1
                'regularization': 0.01, # ë…¼ë¬¸ ê¶Œì¥: 0.001-0.1
                'iterations': 100       # ë…¼ë¬¸ ê¶Œì¥: 50-200
            }
        }

    def _setup_logger(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def load_data(self) -> bool:
        """ë…¼ë¬¸ ì‹¤í—˜ìš© í˜„ì‹¤ì  ë°ì´í„° ìƒì„±"""
        try:
            # ëŒ€ê·œëª¨ í˜„ì‹¤ì  ë°ì´í„°ì…‹ ìƒì„± (ë…¼ë¬¸ í‰ê°€ ê¸°ì¤€)
            self._create_academic_dataset()
            self._prepare_interaction_matrices()

            self.logger.info(f"Academic dataset loaded: {len(self.car_data)} items, {len(self.user_ratings)} interactions")
            return True

        except Exception as e:
            self.logger.error(f"Data loading failed: {e}")
            return False

    def _create_academic_dataset(self):
        """ë…¼ë¬¸ í‰ê°€ë¥¼ ìœ„í•œ ëŒ€ê·œëª¨ í˜„ì‹¤ì  ë°ì´í„°ì…‹"""
        np.random.seed(42)

        # 1. ì°¨ëŸ‰ ë°ì´í„° (500ê°œ - ë…¼ë¬¸ ì‹¤í—˜ ê·œëª¨)
        car_data = []
        makes = ['í˜„ëŒ€', 'ê¸°ì•„', 'BMW', 'ë²¤ì¸ ', 'ì•„ìš°ë””', 'í† ìš”íƒ€', 'í˜¼ë‹¤', 'í­ìŠ¤ë°”ê²', 'ë³¼ë³´', 'í…ŒìŠ¬ë¼', 'ë ‰ì„œìŠ¤', 'ì œë„¤ì‹œìŠ¤']
        categories = ['ì†Œí˜•', 'ì¤‘í˜•', 'ëŒ€í˜•', 'ì»´íŒ©íŠ¸SUV', 'ì¤‘í˜•SUV', 'ëŒ€í˜•SUV', 'ëŸ­ì…”ë¦¬', 'ìŠ¤í¬ì¸ ', 'ì „ê¸°ì°¨', 'í•˜ì´ë¸Œë¦¬ë“œ']
        fuel_types = ['ê°€ì†”ë¦°', 'ë””ì ¤', 'í•˜ì´ë¸Œë¦¬ë“œ', 'ì „ê¸°', 'LPG']

        for i in range(1, 501):  # 500ê°œ ì°¨ëŸ‰
            make = np.random.choice(makes)
            category = np.random.choice(categories)

            # ë¸Œëœë“œë³„ í˜„ì‹¤ì  ê°€ê²© ë¶„í¬
            if make in ['BMW', 'ë²¤ì¸ ', 'ì•„ìš°ë””', 'ë ‰ì„œìŠ¤']:
                price = np.random.randint(4000, 15000)
            elif make == 'í…ŒìŠ¬ë¼':
                price = np.random.randint(5000, 20000)
            elif make in ['í˜„ëŒ€', 'ê¸°ì•„']:
                price = np.random.randint(1500, 8000)
            else:
                price = np.random.randint(2000, 10000)

            car_data.append({
                'id': i,
                'make': make,
                'model': f'{make}_{category}_{i}',
                'year': np.random.randint(2015, 2024),
                'price': price,
                'fuel_type': np.random.choice(fuel_types),
                'category': category,
                'engine_size': round(np.random.uniform(1.0, 4.0), 1),
                'fuel_efficiency': np.random.randint(6, 30),
                'transmission': np.random.choice(['ìˆ˜ë™', 'ìë™', 'CVT']),
                'safety_rating': np.random.randint(3, 6),
                'features': np.random.choice(['basic', 'premium', 'luxury']),
                'description': f'{category} {make} ì°¨ëŸ‰'
            })

        self.car_data = pd.DataFrame(car_data)

        # 2. ì‚¬ìš©ì ë°ì´í„° (200ëª… - ë…¼ë¬¸ ì‹¤í—˜ ê·œëª¨)
        user_data = []
        for user_id in range(1, 201):
            user_data.append({
                'user_id': user_id,
                'age': np.random.randint(20, 65),
                'income': np.random.randint(2000, 12000),
                'family_size': np.random.randint(1, 6),
                'location': np.random.choice(['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°']),
                'driving_experience': np.random.randint(1, 30),
                'preferred_make': np.random.choice(makes),
                'preferred_category': np.random.choice(categories)
            })

        self.user_features = pd.DataFrame(user_data)

        # 3. í˜„ì‹¤ì  í‰ì  ë°ì´í„° ìƒì„± (Sparse Matrix)
        ratings_data = []

        for user_id in range(1, 201):
            user_info = self.user_features[self.user_features['user_id'] == user_id].iloc[0]

            # ì‚¬ìš©ìë³„ í‰ì  íŒ¨í„´ ì •ì˜
            preferred_make = user_info['preferred_make']
            preferred_category = user_info['preferred_category']
            budget_max = user_info['income'] * 0.8  # ì†Œë“ì˜ 80%ê°€ ì˜ˆì‚° ìƒí•œ

            # ê° ì‚¬ìš©ìëŠ” ì „ì²´ ì°¨ëŸ‰ì˜ 5-10%ë§Œ í‰ê°€ (í˜„ì‹¤ì  sparse matrix)
            n_ratings = np.random.randint(25, 51)  # 25-50ê°œ í‰ì 
            car_ids = np.random.choice(range(1, 501), n_ratings, replace=False)

            for car_id in car_ids:
                car_info = self.car_data[self.car_data['id'] == car_id].iloc[0]

                # ë…¼ë¬¸ ê¸°ë°˜ í‰ì  ìƒì„± ë¡œì§
                base_rating = 3.0

                # ë¸Œëœë“œ ì„ í˜¸ë„ ì˜í–¥ (ê°•í•¨)
                if car_info['make'] == preferred_make:
                    base_rating += 1.2
                elif car_info['make'] in ['BMW', 'ë²¤ì¸ ', 'ì•„ìš°ë””', 'ë ‰ì„œìŠ¤']:
                    base_rating += 0.4  # í”„ë¦¬ë¯¸ì—„ ë¸Œëœë“œ ë³´ë„ˆìŠ¤

                # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
                if car_info['category'] == preferred_category:
                    base_rating += 0.8

                # ì˜ˆì‚° ì í•©ì„± (ë§¤ìš° ì¤‘ìš”)
                if car_info['price'] <= budget_max:
                    base_rating += 0.6
                elif car_info['price'] > budget_max * 1.5:
                    base_rating -= 1.0  # ì˜ˆì‚° ì´ˆê³¼ í˜ë„í‹°

                # ì—°ë¹„ ê³ ë ¤ (í™˜ê²½ ì˜ì‹)
                if car_info['fuel_efficiency'] >= 20:
                    base_rating += 0.4
                elif car_info['fuel_efficiency'] <= 10:
                    base_rating -= 0.3

                # ì•ˆì „ì„± ê³ ë ¤
                base_rating += (car_info['safety_rating'] - 3) * 0.3

                # ì—°ë ¹ëŒ€ë³„ ì„ í˜¸ë„
                age = user_info['age']
                if age < 30:  # ì Šì€ì¸µ: ìŠ¤í¬ì¸ , ì—°ë¹„ ì„ í˜¸
                    if car_info['category'] == 'ìŠ¤í¬ì¸ ':
                        base_rating += 0.5
                    if car_info['fuel_type'] in ['í•˜ì´ë¸Œë¦¬ë“œ', 'ì „ê¸°']:
                        base_rating += 0.4
                elif age > 50:  # ì¥ë…„ì¸µ: ëŸ­ì…”ë¦¬, ì•ˆì „ì„± ì„ í˜¸
                    if car_info['category'] == 'ëŸ­ì…”ë¦¬':
                        base_rating += 0.6
                    if car_info['safety_rating'] == 5:
                        base_rating += 0.4

                # ë…¸ì´ì¦ˆ ì¶”ê°€ ë° ìŠ¤ì¼€ì¼ ì¡°ì •
                noise = np.random.normal(0, 0.4)
                final_rating = np.clip(base_rating + noise, 1.0, 5.0)

                # ì•”ì‹œì  í”¼ë“œë°±ë„ ìƒì„± (í´ë¦­, ì¡°íšŒ ë“±)
                implicit_score = final_rating  # ëª…ì‹œì  í‰ì  ê¸°ë°˜
                if final_rating >= 4.0:
                    implicit_score += np.random.uniform(0.5, 1.0)  # ë†’ì€ í‰ì  â†’ ë” ë§ì€ ìƒí˜¸ì‘ìš©

                ratings_data.append({
                    'user_id': user_id,
                    'car_id': int(car_id),
                    'rating': round(final_rating, 1),
                    'implicit_score': round(implicit_score, 2),
                    'timestamp': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 365)),
                    'interaction_type': np.random.choice(['view', 'like', 'inquiry', 'test_drive'],
                                                       p=[0.6, 0.25, 0.10, 0.05])
                })

        self.user_ratings = pd.DataFrame(ratings_data)

        # ë°ì´í„°ì…‹ í†µê³„ ì¶œë ¥ (ë…¼ë¬¸ ìŠ¤íƒ€ì¼)
        self.logger.info(f"""
        ğŸ“ Academic Dataset Statistics:
        - Users: {len(self.user_features)}
        - Items: {len(self.car_data)}
        - Interactions: {len(self.user_ratings)}
        - Sparsity: {1 - len(self.user_ratings) / (len(self.user_features) * len(self.car_data)):.4f}
        - Avg ratings per user: {len(self.user_ratings) / len(self.user_features):.1f}
        - Avg ratings per item: {len(self.user_ratings) / len(self.car_data):.1f}
        """)

    def _prepare_interaction_matrices(self):
        """ìƒí˜¸ì‘ìš© í–‰ë ¬ ì¤€ë¹„ (ë…¼ë¬¸ í‰ê°€ìš©)"""
        try:
            # Surpriseìš© ë°ì´í„°ì…‹
            reader = Reader(rating_scale=(1, 5))
            self.surprise_data = Dataset.load_from_df(
                self.user_ratings[['user_id', 'car_id', 'rating']], reader
            )

            # Implicitìš© sparse matrix
            from scipy.sparse import csr_matrix

            # ì‚¬ìš©ì-ì•„ì´í…œ ë§¤í•‘
            user_ids = self.user_ratings['user_id'].unique()
            item_ids = self.car_data['id'].unique()

            user_to_idx = {uid: idx for idx, uid in enumerate(user_ids)}
            item_to_idx = {iid: idx for idx, iid in enumerate(item_ids)}

            # Implicit ì ìˆ˜ ê¸°ë°˜ sparse matrix
            rows = [user_to_idx[uid] for uid in self.user_ratings['user_id']]
            cols = [item_to_idx[iid] for iid in self.user_ratings['car_id']]
            data = self.user_ratings['implicit_score'].values

            self.interaction_matrix = csr_matrix(
                (data, (rows, cols)),
                shape=(len(user_ids), len(item_ids))
            )

            # ë§¤í•‘ ì €ì¥
            self.user_to_idx = user_to_idx
            self.item_to_idx = item_to_idx
            self.idx_to_user = {idx: uid for uid, idx in user_to_idx.items()}
            self.idx_to_item = {idx: iid for iid, idx in item_to_idx.items()}

            self.logger.info("âœ… Interaction matrices prepared for all algorithms")

        except Exception as e:
            self.logger.error(f"Matrix preparation failed: {e}")

    def train_all_models(self) -> Dict[str, bool]:
        """ëª¨ë“  ë…¼ë¬¸ ê¸°ë°˜ ëª¨ë¸ í›ˆë ¨"""
        results = {}

        # 1. Matrix Factorization (Koren, 2009)
        if SURPRISE_AVAILABLE:
            results['matrix_factorization'] = self._train_matrix_factorization()

        # 2. Neural Collaborative Filtering (He et al. 2017)
        if TENSORFLOW_AVAILABLE:
            results['neural_cf'] = self._train_neural_cf()

        # 3. Hybrid LightFM (Kula, 2015)
        if LIGHTFM_AVAILABLE:
            results['hybrid_lightfm'] = self._train_lightfm()

        # 4. BPR (Rendle et al. 2009)
        if IMPLICIT_AVAILABLE:
            results['bpr_implicit'] = self._train_bpr()

        self.is_trained = any(results.values())

        self.logger.info(f"Model training results: {results}")
        return results

    def _train_matrix_factorization(self) -> bool:
        """Matrix Factorization (Koren, 2009) í›ˆë ¨"""
        try:
            # ë…¼ë¬¸ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ SVD í›ˆë ¨
            params = self.hyperparameters['surprise_svd']

            # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  (ë…¼ë¬¸ í‘œì¤€: 80/20)
            trainset, testset = train_test_split(self.surprise_data, test_size=0.2, random_state=42)

            # SVD ëª¨ë¸ (Koren, 2009 ë°©ë²•ë¡ )
            svd_model = SVD(
                n_factors=params['n_factors'],
                lr_all=params['lr_all'],
                reg_all=params['reg_all'],
                n_epochs=params['n_epochs'],
                random_state=42
            )

            # ëª¨ë¸ í›ˆë ¨
            svd_model.fit(trainset)

            # ì„±ëŠ¥ í‰ê°€ (ë…¼ë¬¸ ìŠ¤íƒ€ì¼)
            predictions = svd_model.test(testset)
            rmse = accuracy.rmse(predictions, verbose=False)
            mae = accuracy.mae(predictions, verbose=False)

            self.models['matrix_factorization'] = {
                'model': svd_model,
                'trainset': trainset,
                'rmse': rmse,
                'mae': mae,
                'algorithm': 'SVD (Koren, 2009)'
            }

            self.logger.info(f"âœ… Matrix Factorization trained - RMSE: {rmse:.3f}, MAE: {mae:.3f}")
            return True

        except Exception as e:
            self.logger.error(f"Matrix Factorization training failed: {e}")
            return False

    def _train_neural_cf(self) -> bool:
        """Neural Collaborative Filtering (He et al. 2017) í›ˆë ¨"""
        try:
            params = self.hyperparameters['neural_cf']

            # ë°ì´í„° ì¤€ë¹„
            n_users = len(self.user_ratings['user_id'].unique())
            n_items = len(self.car_data['id'].unique())

            # NCF ëª¨ë¸ êµ¬ì„± (He et al. 2017 ì•„í‚¤í…ì²˜)
            user_input = keras.Input(shape=(), name='user_id')
            item_input = keras.Input(shape=(), name='item_id')

            # Embedding layers
            user_embedding_gmf = keras.layers.Embedding(
                n_users, params['embedding_dim'], name='user_embedding_gmf'
            )(user_input)
            item_embedding_gmf = keras.layers.Embedding(
                n_items, params['embedding_dim'], name='item_embedding_gmf'
            )(item_input)

            user_embedding_mlp = keras.layers.Embedding(
                n_users, params['embedding_dim'], name='user_embedding_mlp'
            )(user_input)
            item_embedding_mlp = keras.layers.Embedding(
                n_items, params['embedding_dim'], name='item_embedding_mlp'
            )(item_input)

            # Flatten embeddings
            user_vec_gmf = keras.layers.Flatten()(user_embedding_gmf)
            item_vec_gmf = keras.layers.Flatten()(item_embedding_gmf)
            user_vec_mlp = keras.layers.Flatten()(user_embedding_mlp)
            item_vec_mlp = keras.layers.Flatten()(item_embedding_mlp)

            # GMF part (Generalized Matrix Factorization)
            gmf_vector = keras.layers.Multiply()([user_vec_gmf, item_vec_gmf])

            # MLP part
            mlp_vector = keras.layers.Concatenate()([user_vec_mlp, item_vec_mlp])

            for units in params['hidden_units']:
                mlp_vector = keras.layers.Dense(
                    units,
                    activation='relu',
                    kernel_regularizer=keras.regularizers.l2(params['regularization'])
                )(mlp_vector)
                mlp_vector = keras.layers.Dropout(params['dropout_rate'])(mlp_vector)

            # NeuMF layer (Neural Matrix Factorization)
            neumf_vector = keras.layers.Concatenate()([gmf_vector, mlp_vector])
            output = keras.layers.Dense(1, activation='linear', name='prediction')(neumf_vector)

            # ëª¨ë¸ ì»´íŒŒì¼
            model = keras.Model(inputs=[user_input, item_input], outputs=output)
            model.compile(
                optimizer=keras.optimizers.Adam(params['learning_rate']),
                loss='mse',
                metrics=['mae']
            )

            # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
            user_ids = self.user_ratings['user_id'].values - 1  # 0-based indexing
            item_ids = self.user_ratings['car_id'].values - 1
            ratings = self.user_ratings['rating'].values

            # ëª¨ë¸ í›ˆë ¨
            history = model.fit(
                [user_ids, item_ids], ratings,
                epochs=20,
                batch_size=256,
                validation_split=0.2,
                verbose=0
            )

            self.models['neural_cf'] = {
                'model': model,
                'history': history,
                'val_loss': min(history.history['val_loss']),
                'algorithm': 'Neural CF (He et al. 2017)'
            }

            val_loss = min(history.history['val_loss'])
            self.logger.info(f"âœ… Neural CF trained - Val Loss: {val_loss:.3f}")
            return True

        except Exception as e:
            self.logger.error(f"Neural CF training failed: {e}")
            return False

    def _train_lightfm(self) -> bool:
        """LightFM Hybrid (Kula, 2015) í›ˆë ¨"""
        try:
            params = self.hyperparameters['lightfm']

            # LightFM ë°ì´í„°ì…‹ ì¤€ë¹„
            dataset = LFMDataset()

            # ì‚¬ìš©ìì™€ ì•„ì´í…œ í”¼íŒ…
            user_ids = self.user_ratings['user_id'].unique()
            item_ids = self.car_data['id'].unique()

            dataset.fit(users=user_ids, items=item_ids)

            # ìƒí˜¸ì‘ìš© í–‰ë ¬ êµ¬ì„±
            interactions, weights = dataset.build_interactions(
                [(row['user_id'], row['car_id'], row['rating'])
                 for _, row in self.user_ratings.iterrows()]
            )

            # LightFM ëª¨ë¸ í›ˆë ¨ (Kula, 2015 ë°©ë²•ë¡ )
            model = LightFM(
                no_components=params['no_components'],
                learning_rate=params['learning_rate'],
                loss=params['loss'],
                item_alpha=params['item_alpha'],
                user_alpha=params['user_alpha'],
                random_state=42
            )

            model.fit(
                interactions,
                epochs=params['epochs'],
                num_threads=4,
                verbose=False
            )

            # ì„±ëŠ¥ í‰ê°€
            train_auc = auc_score(model, interactions).mean()

            self.models['hybrid_lightfm'] = {
                'model': model,
                'dataset': dataset,
                'interactions': interactions,
                'train_auc': train_auc,
                'algorithm': 'LightFM Hybrid (Kula, 2015)'
            }

            self.logger.info(f"âœ… LightFM Hybrid trained - AUC: {train_auc:.3f}")
            return True

        except Exception as e:
            self.logger.error(f"LightFM training failed: {e}")
            return False

    def _train_bpr(self) -> bool:
        """BPR (Rendle et al. 2009) í›ˆë ¨"""
        try:
            params = self.hyperparameters['bpr_implicit']

            # BPR ëª¨ë¸ í›ˆë ¨ (Rendle et al. 2009 ë°©ë²•ë¡ )
            model = BayesianPersonalizedRanking(
                factors=params['factors'],
                learning_rate=params['learning_rate'],
                regularization=params['regularization'],
                iterations=params['iterations'],
                random_state=42
            )

            # ëª¨ë¸ í›ˆë ¨ (implicit library ì‚¬ìš©)
            model.fit(self.interaction_matrix)

            self.models['bpr_implicit'] = {
                'model': model,
                'interaction_matrix': self.interaction_matrix,
                'algorithm': 'BPR (Rendle et al. 2009)'
            }

            self.logger.info("âœ… BPR trained successfully")
            return True

        except Exception as e:
            self.logger.error(f"BPR training failed: {e}")
            return False

    def get_academic_recommendations(self, user_profile: Dict[str, Any], n_recommendations: int = 5) -> Dict[str, List[Dict]]:
        """ë…¼ë¬¸ë³„ ì¶”ì²œ ê²°ê³¼ ë° ì•™ìƒë¸”"""
        if not self.is_trained:
            self.train_all_models()

        results = {}

        # ê° ë…¼ë¬¸ ë°©ë²•ë¡ ë³„ ì¶”ì²œ
        for model_name, model_data in self.models.items():
            try:
                if model_name == 'matrix_factorization':
                    results[model_name] = self._recommend_matrix_factorization(user_profile, n_recommendations)
                elif model_name == 'neural_cf':
                    results[model_name] = self._recommend_neural_cf(user_profile, n_recommendations)
                elif model_name == 'hybrid_lightfm':
                    results[model_name] = self._recommend_lightfm(user_profile, n_recommendations)
                elif model_name == 'bpr_implicit':
                    results[model_name] = self._recommend_bpr(user_profile, n_recommendations)

            except Exception as e:
                self.logger.error(f"Recommendation failed for {model_name}: {e}")
                results[model_name] = []

        # ì•™ìƒë¸” ì¶”ì²œ
        results['ensemble'] = self._ensemble_academic_recommendations(results, n_recommendations)

        return results

    def _recommend_matrix_factorization(self, user_profile: Dict[str, Any], n_recommendations: int) -> List[Dict]:
        """Matrix Factorization ì¶”ì²œ"""
        try:
            user_id = user_profile.get('user_id', 1)
            model_data = self.models['matrix_factorization']
            model = model_data['model']

            # ì‚¬ìš©ìê°€ í‰ê°€í•˜ì§€ ì•Šì€ ì•„ì´í…œë“¤
            user_rated_items = set(self.user_ratings[self.user_ratings['user_id'] == user_id]['car_id'])
            unrated_items = []

            for car_id in self.car_data['id']:
                if car_id not in user_rated_items:
                    prediction = model.predict(user_id, car_id)
                    unrated_items.append((car_id, prediction.est))

            # ìƒìœ„ ì¶”ì²œ
            top_items = sorted(unrated_items, key=lambda x: x[1], reverse=True)[:n_recommendations]

            recommendations = []
            for car_id, score in top_items:
                car_info = self.car_data[self.car_data['id'] == car_id].iloc[0]
                recommendations.append({
                    'car_id': int(car_id),
                    'score': float(score),
                    'algorithm': 'Matrix Factorization (Koren, 2009)',
                    'reason': 'SVD ê¸°ë°˜ ì ì¬ ìš”ì¸ ë¶„ì„',
                    'paper': 'Matrix Factorization Techniques for RS',
                    **car_info.to_dict()
                })

            return recommendations

        except Exception as e:
            self.logger.error(f"Matrix Factorization recommendation failed: {e}")
            return []

    def _recommend_neural_cf(self, user_profile: Dict[str, Any], n_recommendations: int) -> List[Dict]:
        """Neural CF ì¶”ì²œ"""
        try:
            user_id = user_profile.get('user_id', 1)
            model = self.models['neural_cf']['model']

            # ì‚¬ìš©ìê°€ í‰ê°€í•˜ì§€ ì•Šì€ ì•„ì´í…œë“¤
            user_rated_items = set(self.user_ratings[self.user_ratings['user_id'] == user_id]['car_id'])
            unrated_items = []

            for car_id in self.car_data['id']:
                if car_id not in user_rated_items:
                    # 0-based indexing for prediction
                    prediction = model.predict([user_id - 1, car_id - 1])[0][0]
                    unrated_items.append((car_id, prediction))

            # ìƒìœ„ ì¶”ì²œ
            top_items = sorted(unrated_items, key=lambda x: x[1], reverse=True)[:n_recommendations]

            recommendations = []
            for car_id, score in top_items:
                car_info = self.car_data[self.car_data['id'] == car_id].iloc[0]
                recommendations.append({
                    'car_id': int(car_id),
                    'score': float(score),
                    'algorithm': 'Neural Collaborative Filtering (He et al. 2017)',
                    'reason': 'ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© í•™ìŠµ',
                    'paper': 'Neural Collaborative Filtering',
                    **car_info.to_dict()
                })

            return recommendations

        except Exception as e:
            self.logger.error(f"Neural CF recommendation failed: {e}")
            return []

    def _recommend_lightfm(self, user_profile: Dict[str, Any], n_recommendations: int) -> List[Dict]:
        """LightFM í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ"""
        try:
            user_id = user_profile.get('user_id', 1)
            model_data = self.models['hybrid_lightfm']
            model = model_data['model']

            # LightFMìœ¼ë¡œ ì¶”ì²œ (ê°„ì†Œí™”ëœ ë²„ì „)
            recommendations = []

            # ì„ì‹œë¡œ ìƒìœ„ ì°¨ëŸ‰ë“¤ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” LightFM ì¶”ì²œ ë¡œì§ í•„ìš”)
            for i, car_id in enumerate(self.car_data['id'][:n_recommendations]):
                car_info = self.car_data[self.car_data['id'] == car_id].iloc[0]
                recommendations.append({
                    'car_id': int(car_id),
                    'score': 0.8 - i * 0.05,
                    'algorithm': 'LightFM Hybrid (Kula, 2015)',
                    'reason': 'í˜‘ì—…í•„í„°ë§ + ì½˜í…ì¸  ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ',
                    'paper': 'Learning Hybrid Recommender Systems',
                    **car_info.to_dict()
                })

            return recommendations

        except Exception as e:
            self.logger.error(f"LightFM recommendation failed: {e}")
            return []

    def _recommend_bpr(self, user_profile: Dict[str, Any], n_recommendations: int) -> List[Dict]:
        """BPR ì¶”ì²œ"""
        try:
            user_id = user_profile.get('user_id', 1)
            model = self.models['bpr_implicit']['model']

            # BPR ì¶”ì²œ (ê°„ì†Œí™”ëœ ë²„ì „)
            if user_id in self.user_to_idx:
                user_idx = self.user_to_idx[user_id]

                # BPR ì¶”ì²œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                recommended_items, scores = model.recommend(
                    user_idx,
                    self.interaction_matrix[user_idx],
                    N=n_recommendations,
                    filter_already_liked_items=True
                )

                recommendations = []
                for item_idx, score in zip(recommended_items, scores):
                    car_id = self.idx_to_item[item_idx]
                    car_info = self.car_data[self.car_data['id'] == car_id].iloc[0]
                    recommendations.append({
                        'car_id': int(car_id),
                        'score': float(score),
                        'algorithm': 'BPR (Rendle et al. 2009)',
                        'reason': 'Bayesian Personalized Ranking ê¸°ë°˜',
                        'paper': 'BPR: Bayesian Personalized Ranking',
                        **car_info.to_dict()
                    })

                return recommendations
            else:
                return []

        except Exception as e:
            self.logger.error(f"BPR recommendation failed: {e}")
            return []

    def _ensemble_academic_recommendations(self, all_results: Dict[str, List[Dict]], n_recommendations: int) -> List[Dict]:
        """ë…¼ë¬¸ë³„ ê²°ê³¼ ì•™ìƒë¸” (Meta-Learning ì ‘ê·¼)"""
        try:
            # ë…¼ë¬¸ë³„ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥ ê¸°ë°˜)
            weights = {
                'matrix_factorization': 0.25,
                'neural_cf': 0.35,
                'hybrid_lightfm': 0.25,
                'bpr_implicit': 0.15
            }

            car_scores = {}

            for method, recommendations in all_results.items():
                if method == 'ensemble':  # ìê¸° ìì‹  ì œì™¸
                    continue

                weight = weights.get(method, 0.2)

                for rec in recommendations:
                    car_id = rec['car_id']
                    if car_id not in car_scores:
                        car_scores[car_id] = {
                            'total_score': 0,
                            'methods': [],
                            'papers': [],
                            'car_info': rec
                        }

                    car_scores[car_id]['total_score'] += rec['score'] * weight
                    car_scores[car_id]['methods'].append(rec['algorithm'])
                    car_scores[car_id]['papers'].append(rec['paper'])

            # ìµœì¢… ì¶”ì²œ ìˆœìœ„
            final_recommendations = []
            for car_id, data in sorted(car_scores.items(),
                                     key=lambda x: x[1]['total_score'],
                                     reverse=True)[:n_recommendations]:

                rec = {
                    'car_id': car_id,
                    'score': round(data['total_score'], 3),
                    'algorithm': 'Academic Ensemble',
                    'methods': data['methods'],
                    'papers': list(set(data['papers'])),
                    'reason': f'{len(data["methods"])}ê°œ ë…¼ë¬¸ ì•Œê³ ë¦¬ì¦˜ ì¢…í•© ì¶”ì²œ',
                    'confidence': min(data['total_score'], 1.0)
                }

                # ì°¨ëŸ‰ ì •ë³´ ì¶”ê°€
                car_info = data['car_info']
                for key, value in car_info.items():
                    if key not in ['score', 'algorithm', 'reason', 'paper']:
                        rec[key] = value

                final_recommendations.append(rec)

            return final_recommendations

        except Exception as e:
            self.logger.error(f"Ensemble failed: {e}")
            return []

    def evaluate_academic_performance(self) -> Dict[str, Dict[str, float]]:
        """ë…¼ë¬¸ ê¸°ì¤€ ì„±ëŠ¥ í‰ê°€"""
        evaluation_results = {}

        for model_name, model_data in self.models.items():
            try:
                if model_name == 'matrix_factorization':
                    evaluation_results[model_name] = {
                        'RMSE': model_data['rmse'],
                        'MAE': model_data['mae'],
                        'paper': 'Koren, 2009'
                    }
                elif model_name == 'neural_cf':
                    evaluation_results[model_name] = {
                        'Val_Loss': model_data['val_loss'],
                        'paper': 'He et al., 2017'
                    }
                elif model_name == 'hybrid_lightfm':
                    evaluation_results[model_name] = {
                        'AUC': model_data['train_auc'],
                        'paper': 'Kula, 2015'
                    }
                elif model_name == 'bpr_implicit':
                    evaluation_results[model_name] = {
                        'algorithm': 'BPR',
                        'paper': 'Rendle et al., 2009'
                    }

            except Exception as e:
                self.logger.error(f"Evaluation failed for {model_name}: {e}")

        return evaluation_results

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
academic_recommendation_system = None

def get_academic_system():
    """ë…¼ë¬¸ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹±ê¸€í†¤"""
    global academic_recommendation_system
    if academic_recommendation_system is None:
        academic_recommendation_system = AcademicCarRecommendationSystem()
        if academic_recommendation_system.load_data():
            academic_recommendation_system.train_all_models()
    return academic_recommendation_system

if __name__ == "__main__":
    # ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("ğŸ“ Academic Car Recommendation System")
    print("=" * 50)

    system = get_academic_system()

    # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì
    test_user = {
        'user_id': 1,
        'age': 30,
        'income': 5000,
        'category': 'ì¤‘í˜•SUV',
        'fuel_type': 'í•˜ì´ë¸Œë¦¬ë“œ'
    }

    # ë…¼ë¬¸ë³„ ì¶”ì²œ í…ŒìŠ¤íŠ¸
    recommendations = system.get_academic_recommendations(test_user, n_recommendations=5)

    print("\nğŸ“š Academic Recommendations:")
    for method, recs in recommendations.items():
        print(f"\n{method.upper()}:")
        for i, rec in enumerate(recs[:3], 1):
            print(f"  {i}. {rec.get('make', 'Unknown')} {rec.get('model', 'Unknown')} - Score: {rec.get('score', 0):.3f}")

    # ì„±ëŠ¥ í‰ê°€
    performance = system.evaluate_academic_performance()
    print(f"\nğŸ“Š Performance Evaluation:")
    for model, metrics in performance.items():
        print(f"  {model}: {metrics}")