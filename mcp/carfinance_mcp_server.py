# -*- coding: utf-8 -*-
"""
CarFinanceAI MCP Server
Model Context Protocol ì„œë²„ êµ¬í˜„ - ì¶”ì²œì‹œìŠ¤í…œì„ MCP ì„œë¹„ìŠ¤ë¡œ ì œê³µ
"""

import asyncio
import logging
import json
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass, asdict
import os
from pathlib import Path

# MCP í”„ë¡œí† ì½œ (ê°€ìƒ êµ¬í˜„ - ì‹¤ì œ MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ëŒ€ì²´)
from typing import Protocol, runtime_checkable

# ë‚´ë¶€ ëª¨ë“ˆ
from ..database.connection import DatabaseManager
from ..database.realtime_learning import get_realtime_engine, get_recommendation_cache
from ..agents.gemini_recommendation_agent import get_gemini_multi_agent_system

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@runtime_checkable
class MCPTool(Protocol):
    """MCP ë„êµ¬ í”„ë¡œí† ì½œ"""
    name: str
    description: str
    input_schema: Dict[str, Any]

@dataclass
class MCPToolResult:
    """MCP ë„êµ¬ ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    content: Any
    error: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

class CarFinanceAITool:
    """CarFinanceAI MCP ë„êµ¬ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, name: str, description: str, input_schema: Dict[str, Any]):
        self.name = name
        self.description = description
        self.input_schema = input_schema

    async def execute(self, **kwargs) -> MCPToolResult:
        """ë„êµ¬ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError

class GetRecommendationsTool(CarFinanceAITool):
    """ì‚¬ìš©ì ì¶”ì²œ ì¡°íšŒ ë„êµ¬"""

    def __init__(self):
        super().__init__(
            name="carfinance__get_recommendations",
            description="ì‚¬ìš©ì ë§ì¶¤ ì°¨ëŸ‰ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤. Gemini ë©€í‹°ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•œ ê³ ë„í™”ëœ ì¶”ì²œ ì œê³µ",
            input_schema={
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ì¶”ì²œì„ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ì ID"
                    },
                    "context": {
                        "type": "object",
                        "description": "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì„¸ì…˜ ë°ì´í„°, í˜„ì¬ ê´€ì‹¬ì‚¬ ë“±)",
                        "properties": {
                            "session_id": {"type": "string"},
                            "current_page": {"type": "string"},
                            "search_query": {"type": "string"},
                            "budget_range": {
                                "type": "object",
                                "properties": {
                                    "min": {"type": "number"},
                                    "max": {"type": "number"}
                                }
                            }
                        }
                    },
                    "recommendation_count": {
                        "type": "integer",
                        "description": "ìš”ì²­í•  ì¶”ì²œ ê°œìˆ˜ (ê¸°ë³¸: 5)",
                        "default": 5,
                        "minimum": 1,
                        "maximum": 20
                    },
                    "use_sequential_thinking": {
                        "type": "boolean",
                        "description": "ë³µì¡í•œ ì¶”ì²œ ë…¼ë¦¬ì— Sequential Thinking MCP ì‚¬ìš© ì—¬ë¶€",
                        "default": true
                    }
                },
                "required": ["user_id"]
            }
        )

    async def execute(self, user_id: str, context: Dict = None, recommendation_count: int = 5, use_sequential_thinking: bool = True) -> MCPToolResult:
        """ì¶”ì²œ ì‹¤í–‰"""
        try:
            # Gemini ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì¡°íšŒ
            gemini_key = os.getenv('GEMINI_API_KEY')
            if not gemini_key:
                return MCPToolResult(
                    success=False,
                    content=None,
                    error="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                )

            multi_agent = await get_gemini_multi_agent_system(gemini_key)

            # Sequential Thinking MCP í™œìš© (ë³µì¡í•œ ì¶”ì²œ ë…¼ë¦¬)
            if use_sequential_thinking:
                reasoning_result = await self._use_sequential_thinking_for_recommendations(
                    user_id, context, recommendation_count
                )
                context = context or {}
                context['reasoning_insights'] = reasoning_result

            # ë©€í‹°ì—ì´ì „íŠ¸ ì¶”ì²œ ìƒì„±
            recommendations = await multi_agent.get_recommendations(user_id, context)

            # ì¶”ì²œ ê°œìˆ˜ ì¡°ì •
            if len(recommendations.get('recommendations', [])) > recommendation_count:
                recommendations['recommendations'] = recommendations['recommendations'][:recommendation_count]

            return MCPToolResult(
                success=True,
                content=recommendations,
                metadata={
                    "tool_name": self.name,
                    "execution_time": datetime.now().isoformat(),
                    "user_id": user_id,
                    "used_sequential_thinking": use_sequential_thinking
                }
            )

        except Exception as e:
            logger.error(f"âŒ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return MCPToolResult(
                success=False,
                content=None,
                error=str(e)
            )

    async def _use_sequential_thinking_for_recommendations(self, user_id: str, context: Dict, count: int) -> Dict:
        """Sequential Thinking MCPë¥¼ í™œìš©í•œ ì¶”ì²œ ë…¼ë¦¬ ë¶„ì„"""
        try:
            # ì‹¤ì œë¡œëŠ” sequential-thinking MCP í˜¸ì¶œ
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            reasoning_prompt = f"""
            ì‚¬ìš©ì {user_id}ì— ëŒ€í•œ ì°¨ëŸ‰ ì¶”ì²œ ë…¼ë¦¬ë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

            ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}
            ìš”ì²­ ì¶”ì²œ ìˆ˜: {count}

            ë‹¤ìŒ ë‹¨ê³„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
            1. ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„
            2. ê³¼ê±° í–‰ë™ íŒ¨í„´ ë¶„ì„
            3. ì‹œì¥ ìƒí™© ê³ ë ¤
            4. ì¶”ì²œ ì „ëµ ìˆ˜ë¦½
            5. ì˜ˆìƒ ê²°ê³¼ í‰ê°€
            """

            # Sequential thinking ê²°ê³¼ (ì‹œë®¬ë ˆì´ì…˜)
            return {
                "reasoning_steps": [
                    "ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì„ í˜¸ë„ ë¶„ì„ ì™„ë£Œ",
                    "ê³¼ê±° í–‰ë™ì—ì„œ SUV ì„ í˜¸ íŒ¨í„´ ë°œê²¬",
                    "í˜„ì¬ ì‹œì¥ì—ì„œ SUV í• ì¸ í”„ë¡œëª¨ì…˜ í™œì„±í™”",
                    "ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìˆ˜ ëª¨ë¸ ìš°ì„  ì¶”ì²œ ì „ëµ",
                    "ë†’ì€ ë§Œì¡±ë„ ì˜ˆìƒ, êµ¬ë§¤ ì „í™˜ ê°€ëŠ¥ì„± 75%"
                ],
                "insights": {
                    "primary_preference": "SUV",
                    "budget_sensitivity": "medium",
                    "purchase_probability": 0.75
                }
            }

        except Exception as e:
            logger.error(f"âŒ Sequential Thinking ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"reasoning_steps": [], "insights": {}}

class AnalyzeBehaviorTool(CarFinanceAITool):
    """ì‚¬ìš©ì í–‰ë™ ë¶„ì„ ë„êµ¬"""

    def __init__(self):
        super().__init__(
            name="carfinance__analyze_behavior",
            description="ì‚¬ìš©ìì˜ í–‰ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Sequential Thinkingì„ í™œìš©í•œ ê¹Šì´ ìˆëŠ” ë¶„ì„",
            input_schema={
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ì ID"
                    },
                    "analysis_period_days": {
                        "type": "integer",
                        "description": "ë¶„ì„ ê¸°ê°„ (ì¼ìˆ˜)",
                        "default": 30,
                        "minimum": 1,
                        "maximum": 365
                    },
                    "include_predictions": {
                        "type": "boolean",
                        "description": "ë¯¸ë˜ í–‰ë™ ì˜ˆì¸¡ í¬í•¨ ì—¬ë¶€",
                        "default": true
                    }
                },
                "required": ["user_id"]
            }
        )

    async def execute(self, user_id: str, analysis_period_days: int = 30, include_predictions: bool = True) -> MCPToolResult:
        """í–‰ë™ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ì‹¤ì‹œê°„ í•™ìŠµ ì—”ì§„ ì¡°íšŒ
            engine = await get_realtime_engine()

            # ì‚¬ìš©ì í–‰ë™ ë°ì´í„° ìˆ˜ì§‘
            behavior_data = await self._collect_behavior_data(user_id, analysis_period_days)

            # Sequential Thinkingì„ í™œìš©í•œ íŒ¨í„´ ë¶„ì„
            pattern_analysis = await self._analyze_patterns_with_sequential_thinking(
                user_id, behavior_data, include_predictions
            )

            # í–‰ë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = {
                "user_id": user_id,
                "analysis_period": analysis_period_days,
                "behavior_summary": self._generate_behavior_summary(behavior_data),
                "pattern_analysis": pattern_analysis,
                "recommendations": self._generate_behavior_recommendations(pattern_analysis),
                "timestamp": datetime.now().isoformat()
            }

            return MCPToolResult(
                success=True,
                content=insights,
                metadata={
                    "tool_name": self.name,
                    "analysis_depth": "deep_sequential",
                    "data_points": len(behavior_data)
                }
            )

        except Exception as e:
            logger.error(f"âŒ í–‰ë™ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return MCPToolResult(
                success=False,
                content=None,
                error=str(e)
            )

    async def _collect_behavior_data(self, user_id: str, days: int) -> List[Dict]:
        """í–‰ë™ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            db_manager = DatabaseManager()
            query = """
                SELECT interaction_type, vehicle_id, timestamp,
                       context_data, engagement_score
                FROM user_interactions
                WHERE user_id = $1
                AND timestamp > NOW() - INTERVAL '%s days'
                ORDER BY timestamp DESC
            """ % days

            async with db_manager.get_connection() as conn:
                rows = await conn.fetch(query, user_id)
                return [dict(row) for row in rows]

        except Exception as e:
            logger.error(f"âŒ í–‰ë™ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    async def _analyze_patterns_with_sequential_thinking(self, user_id: str, behavior_data: List[Dict], include_predictions: bool) -> Dict:
        """Sequential Thinkingì„ í™œìš©í•œ íŒ¨í„´ ë¶„ì„"""
        # ì‹¤ì œë¡œëŠ” sequential-thinking MCP í˜¸ì¶œ
        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜í™˜
        return {
            "interaction_patterns": {
                "peak_hours": ["19:00-21:00", "12:00-13:00"],
                "preferred_brands": ["Toyota", "Honda", "BMW"],
                "average_session_duration": 15.5,
                "conversion_indicators": ["multiple_inquiries", "price_comparisons"]
            },
            "behavioral_segments": {
                "primary_segment": "research_oriented_buyer",
                "secondary_traits": ["price_conscious", "feature_focused"]
            },
            "predictions": {
                "purchase_probability_30_days": 0.68,
                "likely_vehicle_type": "SUV",
                "estimated_budget_range": [25000, 40000]
            } if include_predictions else None
        }

    def _generate_behavior_summary(self, behavior_data: List[Dict]) -> Dict:
        """í–‰ë™ ìš”ì•½ ìƒì„±"""
        if not behavior_data:
            return {"total_interactions": 0, "summary": "í–‰ë™ ë°ì´í„° ì—†ìŒ"}

        interaction_types = {}
        for item in behavior_data:
            interaction_type = item.get('interaction_type', 'unknown')
            interaction_types[interaction_type] = interaction_types.get(interaction_type, 0) + 1

        return {
            "total_interactions": len(behavior_data),
            "interaction_breakdown": interaction_types,
            "most_common_action": max(interaction_types.items(), key=lambda x: x[1])[0] if interaction_types else "none",
            "engagement_level": "high" if len(behavior_data) > 50 else "medium" if len(behavior_data) > 10 else "low"
        }

    def _generate_behavior_recommendations(self, pattern_analysis: Dict) -> List[str]:
        """í–‰ë™ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        recommendations = []

        patterns = pattern_analysis.get('interaction_patterns', {})
        segments = pattern_analysis.get('behavioral_segments', {})

        if segments.get('primary_segment') == 'research_oriented_buyer':
            recommendations.append("ìƒì„¸í•œ ì°¨ëŸ‰ ì •ë³´ì™€ ë¹„êµ ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”")
            recommendations.append("ì „ë¬¸ê°€ ë¦¬ë·° ë° ì‹¤ì‚¬ìš© í›„ê¸°ë¥¼ ê°•ì¡°í•˜ì„¸ìš”")

        if 'price_conscious' in segments.get('secondary_traits', []):
            recommendations.append("í• ì¸ ì •ë³´ì™€ í”„ë¡œëª¨ì…˜ì„ ìš°ì„  í‘œì‹œí•˜ì„¸ìš”")
            recommendations.append("ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìˆ˜ ëª¨ë¸ì„ ì¶”ì²œí•˜ì„¸ìš”")

        return recommendations

class TrackInteractionTool(CarFinanceAITool):
    """ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ì¶”ì  ë„êµ¬"""

    def __init__(self):
        super().__init__(
            name="carfinance__track_interaction",
            description="ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ê³  í•™ìŠµ ì‹œìŠ¤í…œì— ë°˜ì˜í•©ë‹ˆë‹¤",
            input_schema={
                "type": "object",
                "properties": {
                    "user_id": {
                        "type": "string",
                        "description": "ì‚¬ìš©ì ID"
                    },
                    "vehicle_id": {
                        "type": "string",
                        "description": "ì°¨ëŸ‰ ID"
                    },
                    "interaction_type": {
                        "type": "string",
                        "enum": ["view", "like", "inquiry", "compare", "purchase"],
                        "description": "ìƒí˜¸ì‘ìš© ìœ í˜•"
                    },
                    "context": {
                        "type": "object",
                        "description": "ìƒí˜¸ì‘ìš© ì»¨í…ìŠ¤íŠ¸",
                        "properties": {
                            "session_id": {"type": "string"},
                            "duration_seconds": {"type": "number"},
                            "page_source": {"type": "string"},
                            "repeat_visit": {"type": "boolean"}
                        }
                    }
                },
                "required": ["user_id", "vehicle_id", "interaction_type"]
            }
        )

    async def execute(self, user_id: str, vehicle_id: str, interaction_type: str, context: Dict = None) -> MCPToolResult:
        """ìƒí˜¸ì‘ìš© ì¶”ì  ì‹¤í–‰"""
        try:
            # ì‹¤ì‹œê°„ í•™ìŠµ ì—”ì§„ ì¡°íšŒ
            engine = await get_realtime_engine()

            # ìƒí˜¸ì‘ìš© ë°ì´í„° êµ¬ì„±
            interaction_data = {
                "user_id": user_id,
                "vehicle_id": vehicle_id,
                "interaction_type": interaction_type,
                "context": context or {},
                "timestamp": datetime.now().isoformat()
            }

            # ì‹¤ì‹œê°„ ì²˜ë¦¬
            success = await engine.process_user_interaction(interaction_data)

            if success:
                return MCPToolResult(
                    success=True,
                    content={
                        "interaction_tracked": True,
                        "user_id": user_id,
                        "vehicle_id": vehicle_id,
                        "interaction_type": interaction_type,
                        "processed_at": datetime.now().isoformat()
                    },
                    metadata={
                        "tool_name": self.name,
                        "real_time_processing": True
                    }
                )
            else:
                return MCPToolResult(
                    success=False,
                    content=None,
                    error="ìƒí˜¸ì‘ìš© ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                )

        except Exception as e:
            logger.error(f"âŒ ìƒí˜¸ì‘ìš© ì¶”ì  ì‹¤íŒ¨: {e}")
            return MCPToolResult(
                success=False,
                content=None,
                error=str(e)
            )

class CompareVehiclesTool(CarFinanceAITool):
    """ì°¨ëŸ‰ ë¹„êµ ë„êµ¬"""

    def __init__(self):
        super().__init__(
            name="carfinance__compare_vehicles",
            description="ì—¬ëŸ¬ ì°¨ëŸ‰ì„ ë¹„êµí•˜ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤",
            input_schema={
                "type": "object",
                "properties": {
                    "vehicle_ids": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "ë¹„êµí•  ì°¨ëŸ‰ ID ëª©ë¡",
                        "minItems": 2,
                        "maxItems": 5
                    },
                    "comparison_criteria": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["price", "fuel_efficiency", "safety", "performance", "comfort", "reliability"]
                        },
                        "description": "ë¹„êµ ê¸°ì¤€ (ê¸°ë³¸: ëª¨ë“  ê¸°ì¤€)"
                    },
                    "user_id": {
                        "type": "string",
                        "description": "ì‚¬ìš©ì ID (ê°œì¸í™”ëœ ë¹„êµë¥¼ ìœ„í•¨)"
                    }
                },
                "required": ["vehicle_ids"]
            }
        )

    async def execute(self, vehicle_ids: List[str], comparison_criteria: List[str] = None, user_id: str = None) -> MCPToolResult:
        """ì°¨ëŸ‰ ë¹„êµ ì‹¤í–‰"""
        try:
            # ê¸°ë³¸ ë¹„êµ ê¸°ì¤€
            if not comparison_criteria:
                comparison_criteria = ["price", "fuel_efficiency", "safety", "performance", "comfort", "reliability"]

            # ì°¨ëŸ‰ ì •ë³´ ì¡°íšŒ
            vehicles_data = await self._get_vehicles_data(vehicle_ids)

            # ë¹„êµ ë¶„ì„ ìˆ˜í–‰
            comparison_result = await self._perform_comparison(vehicles_data, comparison_criteria, user_id)

            return MCPToolResult(
                success=True,
                content=comparison_result,
                metadata={
                    "tool_name": self.name,
                    "compared_vehicles": len(vehicle_ids),
                    "criteria_count": len(comparison_criteria)
                }
            )

        except Exception as e:
            logger.error(f"âŒ ì°¨ëŸ‰ ë¹„êµ ì‹¤íŒ¨: {e}")
            return MCPToolResult(
                success=False,
                content=None,
                error=str(e)
            )

    async def _get_vehicles_data(self, vehicle_ids: List[str]) -> List[Dict]:
        """ì°¨ëŸ‰ ë°ì´í„° ì¡°íšŒ"""
        try:
            db_manager = DatabaseManager()
            placeholders = ','.join(['$' + str(i+1) for i in range(len(vehicle_ids))])
            query = f"""
                SELECT vehicle_id, make, model, year, price, fuel_type,
                       safety_rating, mpg_city, mpg_highway, features
                FROM vehicles
                WHERE vehicle_id IN ({placeholders})
            """

            async with db_manager.get_connection() as conn:
                rows = await conn.fetch(query, *vehicle_ids)
                return [dict(row) for row in rows]

        except Exception as e:
            logger.error(f"âŒ ì°¨ëŸ‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def _perform_comparison(self, vehicles_data: List[Dict], criteria: List[str], user_id: str = None) -> Dict:
        """ë¹„êµ ë¶„ì„ ìˆ˜í–‰"""
        if not vehicles_data:
            return {"error": "ì°¨ëŸ‰ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        comparison = {
            "vehicles": vehicles_data,
            "comparison_matrix": {},
            "recommendations": [],
            "summary": {}
        }

        # ê° ê¸°ì¤€ë³„ ë¹„êµ
        for criterion in criteria:
            comparison["comparison_matrix"][criterion] = self._compare_by_criterion(vehicles_data, criterion)

        # ì¢…í•© ì¶”ì²œ
        comparison["recommendations"] = self._generate_comparison_recommendations(vehicles_data, criteria, user_id)

        return comparison

    def _compare_by_criterion(self, vehicles: List[Dict], criterion: str) -> Dict:
        """ê¸°ì¤€ë³„ ë¹„êµ"""
        if criterion == "price":
            scores = {v['vehicle_id']: self._price_score(v['price']) for v in vehicles}
        elif criterion == "fuel_efficiency":
            scores = {v['vehicle_id']: self._fuel_score(v.get('mpg_city', 0), v.get('mpg_highway', 0)) for v in vehicles}
        elif criterion == "safety":
            scores = {v['vehicle_id']: v.get('safety_rating', 3) for v in vehicles}
        else:
            # ê¸°ë³¸ ì ìˆ˜
            scores = {v['vehicle_id']: 3.0 for v in vehicles}

        return {
            "scores": scores,
            "winner": max(scores.items(), key=lambda x: x[1])[0],
            "ranking": sorted(scores.items(), key=lambda x: x[1], reverse=True)
        }

    def _price_score(self, price: float) -> float:
        """ê°€ê²© ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
        return max(1.0, 6.0 - (price / 10000))

    def _fuel_score(self, city_mpg: float, highway_mpg: float) -> float:
        """ì—°ë¹„ ì ìˆ˜"""
        avg_mpg = (city_mpg + highway_mpg) / 2
        return min(5.0, avg_mpg / 10)

    def _generate_comparison_recommendations(self, vehicles: List[Dict], criteria: List[str], user_id: str = None) -> List[str]:
        """ë¹„êµ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        recommendations = []

        if len(vehicles) >= 2:
            cheapest = min(vehicles, key=lambda v: v['price'])
            most_efficient = max(vehicles, key=lambda v: (v.get('mpg_city', 0) + v.get('mpg_highway', 0)) / 2)

            recommendations.append(f"ê°€ê²© ìš°ì„ : {cheapest['make']} {cheapest['model']}")
            recommendations.append(f"ì—°ë¹„ ìš°ì„ : {most_efficient['make']} {most_efficient['model']}")

        return recommendations

class CarFinanceAIMCPServer:
    """CarFinanceAI MCP ì„œë²„"""

    def __init__(self):
        self.tools = {
            "carfinance__get_recommendations": GetRecommendationsTool(),
            "carfinance__analyze_behavior": AnalyzeBehaviorTool(),
            "carfinance__track_interaction": TrackInteractionTool(),
            "carfinance__compare_vehicles": CompareVehiclesTool()
        }

        self.server_info = {
            "name": "CarFinanceAI MCP Server",
            "version": "1.0.0",
            "description": "ìë™ì°¨ ê¸ˆìœµ ë° ì¶”ì²œì‹œìŠ¤í…œ MCP ì„œë²„",
            "tools": list(self.tools.keys())
        }

    async def list_tools(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return [
            {
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.input_schema
            }
            for tool in self.tools.values()
        ]

    async def execute_tool(self, tool_name: str, **kwargs) -> MCPToolResult:
        """ë„êµ¬ ì‹¤í–‰"""
        if tool_name not in self.tools:
            return MCPToolResult(
                success=False,
                content=None,
                error=f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"
            )

        tool = self.tools[tool_name]
        return await tool.execute(**kwargs)

    async def get_server_info(self) -> Dict[str, Any]:
        """ì„œë²„ ì •ë³´ ë°˜í™˜"""
        return self.server_info

    async def health_check(self) -> Dict[str, Any]:
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
            db_manager = DatabaseManager()
            async with db_manager.get_connection() as conn:
                await conn.fetchval("SELECT 1")

            return {
                "status": "healthy",
                "timestamp": datetime.now().isoformat(),
                "database": "connected",
                "tools_count": len(self.tools)
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_mcp_server = None

async def get_carfinance_mcp_server() -> CarFinanceAIMCPServer:
    """CarFinanceAI MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ"""
    global _mcp_server

    if _mcp_server is None:
        _mcp_server = CarFinanceAIMCPServer()

    return _mcp_server

# MCP ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
async def run_mcp_server():
    """MCP ì„œë²„ ì‹¤í–‰"""
    server = await get_carfinance_mcp_server()

    logger.info("ğŸš€ CarFinanceAI MCP Server ì‹œì‘")
    logger.info(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(server.tools)}ê°œ")

    # ì„œë²„ ìƒíƒœ í™•ì¸
    health = await server.health_check()
    logger.info(f"ğŸ’š ì„œë²„ ìƒíƒœ: {health['status']}")

    # ë„êµ¬ ëª©ë¡ ì¶œë ¥
    tools = await server.list_tools()
    for tool in tools:
        logger.info(f"ğŸ”§ ë„êµ¬: {tool['name']} - {tool['description']}")

    return server

if __name__ == "__main__":
    asyncio.run(run_mcp_server())