"""
NCF ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¸¡ì • ë° ê²€ì¦
ì‹¤ì œ NCF vs ê¸°ë³¸ ì¶”ì²œ ì‹œìŠ¤í…œ ë¹„êµ í…ŒìŠ¤íŠ¸
"""
import requests
import json
import time
import statistics
from typing import Dict, List
import pandas as pd

# í…ŒìŠ¤íŠ¸ ì„¤ì •
BACKEND_URL = "http://localhost:8000"
TEST_USERS = [
    {
        "user_id": "test_young_professional",
        "age": 28,
        "income": 4500,
        "preferences": ["ì—°ë¹„", "ì•ˆì „ì„±"],
        "budget_range": {"max": 3500}
    },
    {
        "user_id": "test_family_user",
        "age": 35,
        "income": 6000,
        "preferences": ["ê°€ì¡±ìš©", "ë„“ì€ ê³µê°„", "ì•ˆì „ì„±"],
        "budget_range": {"max": 4500}
    },
    {
        "user_id": "test_luxury_user",
        "age": 45,
        "income": 8000,
        "preferences": ["ëŸ­ì…”ë¦¬", "ë¸Œëœë“œ", "ì„±ëŠ¥"],
        "budget_range": {"max": 7000}
    },
    {
        "user_id": "test_budget_user",
        "age": 24,
        "income": 3000,
        "preferences": ["ê°€ê²©", "ì—°ë¹„"],
        "budget_range": {"max": 2500}
    },
    {
        "user_id": "test_eco_user",
        "age": 30,
        "income": 5500,
        "preferences": ["ì¹œí™˜ê²½", "ì „ê¸°ì°¨", "ì—°ë¹„"],
        "budget_range": {"max": 5000}
    }
]

def test_recommendation_api(user_profile: Dict, limit: int = 10) -> Dict:
    """ì¶”ì²œ API í…ŒìŠ¤íŠ¸"""
    url = f"{BACKEND_URL}/api/recommendations"
    payload = {
        "user_profile": user_profile,
        "recommendation_type": "ncf_hybrid",
        "limit": limit
    }

    start_time = time.time()
    try:
        response = requests.post(url, json=payload, timeout=10)
        response_time = time.time() - start_time

        if response.status_code == 200:
            return {
                "success": True,
                "data": response.json(),
                "response_time": response_time,
                "status_code": 200
            }
        else:
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "response_time": response_time,
                "status_code": response.status_code
            }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "response_time": time.time() - start_time,
            "status_code": 0
        }

def analyze_recommendation_quality(recommendations: List[Dict], user_profile: Dict) -> Dict:
    """ì¶”ì²œ í’ˆì§ˆ ë¶„ì„"""
    if not recommendations:
        return {"error": "ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"}

    # 1. ë‹¤ì–‘ì„± ì ìˆ˜ (ì„œë¡œ ë‹¤ë¥¸ ì°¨ëŸ‰ ë¸Œëœë“œ/ëª¨ë¸)
    algorithms = set(rec.get('algorithm', 'unknown') for rec in recommendations)
    diversity_score = len(algorithms) / len(recommendations) if recommendations else 0

    # 2. ì‹ ë¢°ë„ ì ìˆ˜ í‰ê· 
    confidence_scores = [rec.get('confidence', 0) for rec in recommendations]
    avg_confidence = statistics.mean(confidence_scores) if confidence_scores else 0

    # 3. ì¶”ì²œ ì ìˆ˜ ë¶„í¬
    recommendation_scores = [rec.get('score', 0) for rec in recommendations]
    score_variance = statistics.variance(recommendation_scores) if len(recommendation_scores) > 1 else 0

    # 4. ì‚¬ìš©ì ì„ í˜¸ë„ ë§¤ì¹­ ë¶„ì„
    user_preferences = user_profile.get('preferences', [])
    preference_matches = 0

    for rec in recommendations:
        reasons = rec.get('reasons', [])
        for reason in reasons:
            for pref in user_preferences:
                if pref in reason:
                    preference_matches += 1
                    break

    preference_match_rate = preference_matches / len(recommendations) if recommendations else 0

    return {
        "diversity_score": round(diversity_score, 3),
        "avg_confidence": round(avg_confidence, 3),
        "score_variance": round(score_variance, 3),
        "preference_match_rate": round(preference_match_rate, 3),
        "total_recommendations": len(recommendations),
        "avg_score": round(statistics.mean(recommendation_scores), 3) if recommendation_scores else 0
    }

def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§  NCF ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # ë°±ì—”ë“œ ìƒíƒœ í™•ì¸
    try:
        health_response = requests.get(f"{BACKEND_URL}/health", timeout=5)
        health_data = health_response.json()
        print(f"ë°±ì—”ë“œ ìƒíƒœ: {health_data.get('status', 'unknown')}")
        print(f"NCF ëª¨ë¸: {health_data.get('ncf_model', 'unknown')}")
        print("-" * 60)
    except Exception as e:
        print(f"âš ï¸ ë°±ì—”ë“œ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ê° ì‚¬ìš©ìë³„ í…ŒìŠ¤íŠ¸
    all_results = []
    response_times = []

    for i, user in enumerate(TEST_USERS, 1):
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ {i}/5: {user['user_id']}")
        print(f"   ë‚˜ì´: {user['age']}, ì†Œë“: {user['income']}, ì„ í˜¸: {user['preferences']}")

        # API í˜¸ì¶œ
        result = test_recommendation_api(user)
        response_times.append(result['response_time'])

        if result['success']:
            recommendations = result['data'].get('recommendations', [])
            metadata = result['data'].get('metadata', {})

            # ê²°ê³¼ ë¶„ì„
            quality = analyze_recommendation_quality(recommendations, user)

            print(f"   âœ… ì„±ê³µ (ì‘ë‹µì‹œê°„: {result['response_time']:.3f}ì´ˆ)")
            print(f"   ğŸ“ˆ ì¶”ì²œ ê°œìˆ˜: {quality['total_recommendations']}")
            print(f"   ğŸ¯ í‰ê·  ì ìˆ˜: {quality['avg_score']}")
            print(f"   ğŸ” ì‹ ë¢°ë„: {quality['avg_confidence']}")
            print(f"   ğŸ’ ë‹¤ì–‘ì„±: {quality['diversity_score']}")
            print(f"   â¤ï¸ ì„ í˜¸ë„ ë§¤ì¹­: {quality['preference_match_rate']}")
            print(f"   ğŸ¤– ì•Œê³ ë¦¬ì¦˜: {metadata.get('algorithm', 'unknown')}")
            print(f"   ğŸ”§ ëª¨ë“œ: {metadata.get('mode', 'unknown')}")

            # ìƒìœ„ 3ê°œ ì¶”ì²œ ê²°ê³¼ í‘œì‹œ
            print("   ğŸš— ìƒìœ„ 3ê°œ ì¶”ì²œ:")
            for j, rec in enumerate(recommendations[:3], 1):
                print(f"      {j}. {rec.get('vehicle_id', 'unknown')} (ì ìˆ˜: {rec.get('score', 0):.3f})")
                reasons = rec.get('reasons', [])[:2]  # ìƒìœ„ 2ê°œ ì´ìœ ë§Œ
                if reasons:
                    print(f"         ì´ìœ : {', '.join(reasons)}")

            all_results.append({
                'user_id': user['user_id'],
                'success': True,
                'response_time': result['response_time'],
                'quality': quality,
                'algorithm': metadata.get('algorithm', 'unknown'),
                'mode': metadata.get('mode', 'unknown')
            })

        else:
            print(f"   âŒ ì‹¤íŒ¨: {result['error']}")
            print(f"   â±ï¸ ì‘ë‹µì‹œê°„: {result['response_time']:.3f}ì´ˆ")
            all_results.append({
                'user_id': user['user_id'],
                'success': False,
                'error': result['error'],
                'response_time': result['response_time']
            })

    # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½")
    print("=" * 60)

    successful_tests = [r for r in all_results if r['success']]
    success_rate = len(successful_tests) / len(all_results) * 100

    print(f"ì„±ê³µë¥ : {success_rate:.1f}% ({len(successful_tests)}/{len(all_results)})")
    print(f"í‰ê·  ì‘ë‹µì‹œê°„: {statistics.mean(response_times):.3f}ì´ˆ")
    print(f"ìµœëŒ€ ì‘ë‹µì‹œê°„: {max(response_times):.3f}ì´ˆ")
    print(f"ìµœì†Œ ì‘ë‹µì‹œê°„: {min(response_times):.3f}ì´ˆ")

    if successful_tests:
        # í’ˆì§ˆ ì§€í‘œ í‰ê· 
        avg_scores = [r['quality']['avg_score'] for r in successful_tests]
        avg_confidence = [r['quality']['avg_confidence'] for r in successful_tests]
        avg_diversity = [r['quality']['diversity_score'] for r in successful_tests]
        avg_preference_match = [r['quality']['preference_match_rate'] for r in successful_tests]

        print(f"\ní’ˆì§ˆ ì§€í‘œ í‰ê· :")
        print(f"  ğŸ¯ ì¶”ì²œ ì ìˆ˜: {statistics.mean(avg_scores):.3f}")
        print(f"  ğŸ” ì‹ ë¢°ë„: {statistics.mean(avg_confidence):.3f}")
        print(f"  ğŸ’ ë‹¤ì–‘ì„±: {statistics.mean(avg_diversity):.3f}")
        print(f"  â¤ï¸ ì„ í˜¸ë„ ë§¤ì¹­: {statistics.mean(avg_preference_match):.3f}")

        # ì•Œê³ ë¦¬ì¦˜ ë¶„í¬
        algorithms = [r['algorithm'] for r in successful_tests]
        modes = [r['mode'] for r in successful_tests]

        print(f"\nì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜:")
        for algo in set(algorithms):
            count = algorithms.count(algo)
            print(f"  ğŸ“˜ {algo}: {count}íšŒ ({count/len(algorithms)*100:.1f}%)")

        print(f"\nì‹¤í–‰ ëª¨ë“œ:")
        for mode in set(modes):
            count = modes.count(mode)
            print(f"  âš™ï¸ {mode}: {count}íšŒ ({count/len(modes)*100:.1f}%)")

    # NCF ì„±ëŠ¥ í‰ê°€
    print("\n" + "=" * 60)
    print("ğŸ§  NCF ì„±ëŠ¥ í‰ê°€")
    print("=" * 60)

    if success_rate >= 90:
        print("âœ… ìš°ìˆ˜: ì¶”ì²œ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤")
    elif success_rate >= 70:
        print("âš ï¸ ì–‘í˜¸: ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
    else:
        print("âŒ ì£¼ì˜: ì‹œìŠ¤í…œ ì•ˆì •ì„± ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤")

    avg_response = statistics.mean(response_times)
    if avg_response < 0.5:
        print("âš¡ ì‘ë‹µì†ë„: ë§¤ìš° ë¹ ë¦„ (0.5ì´ˆ ë¯¸ë§Œ)")
    elif avg_response < 2.0:
        print("ğŸš€ ì‘ë‹µì†ë„: ë¹ ë¦„ (2ì´ˆ ë¯¸ë§Œ)")
    else:
        print("ğŸŒ ì‘ë‹µì†ë„: ê°œì„  í•„ìš” (2ì´ˆ ì´ìƒ)")

    if successful_tests:
        avg_quality = statistics.mean([r['quality']['avg_score'] for r in successful_tests])
        if avg_quality >= 0.7:
            print("ğŸ¯ ì¶”ì²œ í’ˆì§ˆ: ë†’ìŒ (0.7 ì´ìƒ)")
        elif avg_quality >= 0.5:
            print("ğŸ“Š ì¶”ì²œ í’ˆì§ˆ: ë³´í†µ (0.5-0.7)")
        else:
            print("ğŸ“‰ ì¶”ì²œ í’ˆì§ˆ: ê°œì„  í•„ìš” (0.5 ë¯¸ë§Œ)")

    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
    if all_results:
        df_results = []
        for result in all_results:
            if result['success']:
                row = {
                    'user_id': result['user_id'],
                    'success': result['success'],
                    'response_time': result['response_time'],
                    'algorithm': result['algorithm'],
                    'mode': result['mode'],
                    'avg_score': result['quality']['avg_score'],
                    'confidence': result['quality']['avg_confidence'],
                    'diversity': result['quality']['diversity_score'],
                    'preference_match': result['quality']['preference_match_rate']
                }
            else:
                row = {
                    'user_id': result['user_id'],
                    'success': result['success'],
                    'response_time': result['response_time'],
                    'error': result['error']
                }
            df_results.append(row)

        df = pd.DataFrame(df_results)
        df.to_csv('ncf_performance_test_results.csv', index=False, encoding='utf-8')
        print(f"ğŸ“ ê²°ê³¼ê°€ 'ncf_performance_test_results.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    run_performance_test()