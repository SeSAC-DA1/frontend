# ğŸ¤– ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ì„ íƒ ê°€ì´ë“œ: PyTorch vs TensorFlow/Keras

## ğŸ† **ì¶”ì²œ ê²°ë¡ : PyTorch ì„ íƒ**

### âœ… **PyTorch ì¥ì  (CarFinanceAI ê´€ì )**

#### 1. **ğŸ”¬ ì—°êµ¬ ì¹œí™”ì  - ë…¼ë¬¸ êµ¬í˜„ ìš©ì´**
```python
# PyTorch - NCF ë…¼ë¬¸ êµ¬í˜„ ì˜ˆì‹œ
class NeuralCF(nn.Module):
    def __init__(self, num_users, num_items, embedding_dim):
        super(NeuralCF, self).__init__()

        # GMF layers (ë…¼ë¬¸ì˜ Generalized Matrix Factorization)
        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim)
        self.item_embedding_gmf = nn.Embedding(num_items, embedding_dim)

        # MLP layers (ë…¼ë¬¸ì˜ Multi-Layer Perceptron)
        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)
        self.item_embedding_mlp = nn.Embedding(num_items, embedding_dim)

        # ë…¼ë¬¸ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ì§ê´€ì  êµ¬í˜„
        self.mlp_layers = nn.Sequential(
            nn.Linear(embedding_dim * 2, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64)
        )

        # Final prediction layer
        self.final_layer = nn.Linear(embedding_dim + 64, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, user_ids, item_ids):
        # GMF part
        gmf_user = self.user_embedding_gmf(user_ids)
        gmf_item = self.item_embedding_gmf(item_ids)
        gmf_output = gmf_user * gmf_item  # Element-wise product

        # MLP part
        mlp_user = self.user_embedding_mlp(user_ids)
        mlp_item = self.item_embedding_mlp(item_ids)
        mlp_input = torch.cat([mlp_user, mlp_item], dim=-1)
        mlp_output = self.mlp_layers(mlp_input)

        # Concatenate and predict
        final_input = torch.cat([gmf_output, mlp_output], dim=-1)
        prediction = self.sigmoid(self.final_layer(final_input))

        return prediction
```

#### 2. **âš¡ ë™ì  ê³„ì‚° ê·¸ë˜í”„ - ì‹¤ì‹œê°„ í•™ìŠµ ìµœì í™”**
```python
# ì‹¤ì‹œê°„ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
def update_model_realtime(model, user_feedback):
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë¸ì— ë°˜ì˜"""

    for user_id, item_id, rating, context in user_feedback:
        # ë™ì ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° ë³€ê²½ ê°€ëŠ¥
        batch_data = create_dynamic_batch(user_id, item_id, context)

        # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        optimizer.zero_grad()
        predictions = model(batch_data['users'], batch_data['items'])
        loss = criterion(predictions, batch_data['ratings'])

        # ì¦‰ì‹œ ëª¨ë¸ ì—…ë°ì´íŠ¸ (TensorFlowë³´ë‹¤ ê°„ë‹¨)
        loss.backward()
        optimizer.step()

        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê´€ë¦¬
        del batch_data, predictions, loss
```

#### 3. **ğŸ”§ ë””ë²„ê¹… ìš©ì´ì„± - ê°œë°œ íš¨ìœ¨ì„±**
```python
# PyTorch: ì§ê´€ì ì¸ ë””ë²„ê¹…
def debug_recommendation_model():
    model = NeuralCF(num_users=1000, num_items=500, embedding_dim=64)

    # ì¤‘ê°„ ë‹¨ê³„ë³„ ì¶œë ¥ í™•ì¸ ê°€ëŠ¥
    user_ids = torch.tensor([1, 2, 3])
    item_ids = torch.tensor([10, 20, 30])

    # ê° ë ˆì´ì–´ë³„ ì¶œë ¥ ì§ì ‘ í™•ì¸
    gmf_user = model.user_embedding_gmf(user_ids)
    print(f"GMF User Embedding: {gmf_user.shape}")  # [3, 64]

    # ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì  ìƒíƒœ í™•ì¸
    print(f"Requires Grad: {gmf_user.requires_grad}")  # True

    # ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    if torch.cuda.is_available():
        print(f"GPU Memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
```

#### 4. **ğŸ“š ì¶”ì²œì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœê³„**
```python
# PyTorch ê¸°ë°˜ ì¶”ì²œì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
libraries = {
    'pytorch_lightning': 'íŠ¸ë ˆì´ë‹ íŒŒì´í”„ë¼ì¸ ê°„ì†Œí™”',
    'pytorch_geometric': 'ê·¸ë˜í”„ ê¸°ë°˜ ì¶”ì²œ (Graph Neural Network)',
    'transformers': 'BERT4Rec ë“± Transformer ê¸°ë°˜ ì¶”ì²œ',
    'pytorch_forecasting': 'ì‹œê³„ì—´ ê¸°ë°˜ ìˆ˜ìš” ì˜ˆì¸¡',
    'optuna': 'PyTorch ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”'
}
```

### ğŸ”„ **TensorFlow/Keras ì¥ì **

#### 1. **ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬ ìš©ì´**
```python
# TensorFlow Serving í™œìš©
import tensorflow as tf

# ëª¨ë¸ ì €ì¥ (SavedModel í˜•ì‹)
tf.saved_model.save(model, "ncf_model/1")

# Docker ì»¨í…Œì´ë„ˆë¡œ ì¦‰ì‹œ ì„œë¹™
"""
docker run -p 8501:8501 \
  --mount type=bind,source=$(pwd)/ncf_model,target=/models/ncf \
  -e MODEL_NAME=ncf -t tensorflow/serving
"""
```

#### 2. **ğŸ“± ëª¨ë°”ì¼ ë°°í¬ (TensorFlow Lite)**
```python
# ëª¨ë°”ì¼ ì•±ìš© ê²½ëŸ‰í™”
converter = tf.lite.TFLiteConverter.from_saved_model("ncf_model/1")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# ëª¨ë°”ì¼ì—ì„œ ì¶”ì²œ ì‹¤í–‰ ê°€ëŠ¥
with open('ncf_model.tflite', 'wb') as f:
    f.write(tflite_model)
```

#### 3. **ğŸ¯ TensorFlow Recommenders (TFX)**
```python
import tensorflow_recommenders as tfrs

# ê³ ìˆ˜ì¤€ ì¶”ì²œì‹œìŠ¤í…œ API
class NCFModel(tfrs.Model):
    def __init__(self):
        super().__init__()

        # TFXì˜ ê²€ì¦ëœ ì¶”ì²œ ë ˆì´ì–´ë“¤
        self.embedding_dim = 64
        self.user_embedding = tf.keras.utils.StringLookup(mask_token=None)
        self.item_embedding = tf.keras.utils.StringLookup(mask_token=None)

        # TFX Ranking task (ìë™ ë©”íŠ¸ë¦­ ê³„ì‚°)
        self.ranking_task = tfrs.tasks.Ranking(
            loss=tf.keras.losses.MeanSquaredError(),
            metrics=[tf.keras.metrics.RootMeanSquaredError()]
        )
```

## ğŸ¤” **í”„ë¡œì íŠ¸ë³„ ìƒí™© ë¶„ì„**

### **CarFinanceAI í”„ë¡œì íŠ¸ íŠ¹ì„±**
```yaml
í˜„ì¬_ìƒí™©:
  - ì—°êµ¬ ì¤‘ì‹¬ í”„ë¡œì íŠ¸ (5ê°œ ë…¼ë¬¸ êµ¬í˜„)
  - ì‹¤ì‹œê°„ í•™ìŠµ ìš”êµ¬ì‚¬í•­
  - ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ í•„ìš”
  - íŒ€ ê·œëª¨ ì‘ìŒ (ê°œë°œ íš¨ìœ¨ì„± ì¤‘ìš”)
  - ëª¨ë°”ì¼ ë°°í¬ ê³„íš ì—†ìŒ (í˜„ì¬)

ê¸°ìˆ _ìš”êµ¬ì‚¬í•­:
  - NCF, Wide&Deep, DeepFM ë“± ë³µì¡í•œ ì•„í‚¤í…ì²˜
  - A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¹ ë¥¸ ëª¨ë¸ ì‹¤í—˜
  - ì‚¬ìš©ì í”¼ë“œë°± ì‹¤ì‹œê°„ ë°˜ì˜
  - ë””ë²„ê¹… ë° ì„±ëŠ¥ ë¶„ì„ ì¤‘ìš”
```

## ğŸ† **ìµœì¢… ê¶Œì¥: PyTorch + FastAPI ì¡°í•©**

### **êµ¬í˜„ ì•„í‚¤í…ì²˜**
```python
# ì¶”ì²œ í”„ë¡œì íŠ¸ êµ¬ì¡°
CarFinanceAI/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pytorch_ncf.py           # PyTorch NCF êµ¬í˜„
â”‚   â”œâ”€â”€ wide_deep.py             # Wide & Deep ëª¨ë¸
â”‚   â””â”€â”€ ensemble.py              # ì•™ìƒë¸” ëª¨ë¸
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_ncf.py             # ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ real_time_update.py      # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ pytorch_serving.py       # PyTorch ëª¨ë¸ ì„œë¹™
â”‚   â””â”€â”€ model_cache.py           # ëª¨ë¸ ìºì‹±
â””â”€â”€ evaluation/
    â”œâ”€â”€ metrics.py               # í‰ê°€ ë©”íŠ¸ë¦­
    â””â”€â”€ ab_testing.py            # A/B í…ŒìŠ¤íŠ¸
```

### **ì„±ëŠ¥ ë¹„êµ ì˜ˆìƒ**

| í•­ëª© | PyTorch | TensorFlow/Keras |
|------|---------|------------------|
| **ê°œë°œ ì†ë„** | â­â­â­â­â­ | â­â­â­ |
| **ë””ë²„ê¹…** | â­â­â­â­â­ | â­â­â­ |
| **ë…¼ë¬¸ êµ¬í˜„** | â­â­â­â­â­ | â­â­â­â­ |
| **ì‹¤ì‹œê°„ í•™ìŠµ** | â­â­â­â­â­ | â­â­â­ |
| **í”„ë¡œë•ì…˜ ë°°í¬** | â­â­â­ | â­â­â­â­â­ |
| **ëª¨ë°”ì¼ ì§€ì›** | â­â­ | â­â­â­â­â­ |
| **ì»¤ë®¤ë‹ˆí‹°** | â­â­â­â­â­ | â­â­â­â­ |

### **ê¶Œì¥ í•™ìŠµ ë¡œë“œë§µ**

#### **Week 1-2: PyTorch ê¸°ë³¸**
```python
# 1. PyTorch ê¸°ì´ˆ ìˆ™ë‹¬
basics = [
    'tensor_operations',
    'autograd_mechanics',
    'nn_module_design',
    'custom_datasets',
    'training_loops'
]

# 2. ê°„ë‹¨í•œ ì¶”ì²œ ëª¨ë¸ë¶€í„° ì‹œì‘
simple_models = [
    'matrix_factorization',  # SVD êµ¬í˜„
    'neural_matrix_factorization',  # ê¸°ë³¸ NCF
    'content_based_filtering'
]
```

#### **Week 3-4: ê³ ê¸‰ ëª¨ë¸ êµ¬í˜„**
```python
advanced_models = [
    'neural_collaborative_filtering',  # ë…¼ë¬¸ ì™„ì „ êµ¬í˜„
    'wide_and_deep',
    'deep_fm',
    'real_time_learning'
]
```

## ğŸ¯ **ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„**

### **ê¶Œì¥ì‚¬í•­**
1. **PyTorch ì„ íƒ** - ì—°êµ¬ ì¤‘ì‹¬ í”„ë¡œì íŠ¸ì— ìµœì 
2. **FastAPIì™€ í•¨ê»˜ ì‚¬ìš©** - Python ìƒíƒœê³„ ì¼ê´€ì„±
3. **ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜** - ê¸°ì¡´ TensorFlow ì½”ë“œëŠ” ìœ ì§€í•˜ë©° ìƒˆ ëª¨ë¸ë§Œ PyTorch

### **ì¦‰ì‹œ ì‹œì‘í•  ì‘ì—…**
```bash
# 1. PyTorch ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •
pip install torch torchvision torchaudio pytorch-lightning

# 2. ê¸°ì¡´ NCF ëª¨ë¸ì„ PyTorchë¡œ í¬íŒ…
# 3. PostgreSQL ì—°ë™ ë° ì‹¤ë°ì´í„° í•™ìŠµ
# 4. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ì™€ í†µí•©
```

**PyTorchì˜ í•™ìŠµ ê³¡ì„ ì€ ê°€íŒŒë¥´ì§€ë§Œ, ì¥ê¸°ì ìœ¼ë¡œ ë” ìœ ì—°í•˜ê³  ê°•ë ¥í•œ ì¶”ì²œì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€**